{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"NEMO_CACHE_DIR\"] = \"/usr/src/app/models\"\n",
    "sys.path.insert(0, '/usr/src/app/inference')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "logging.getLogger(\"nemo_logger\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0209 08:16:31.942991 140462456464512 zarr.py:57] `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).\n"
     ]
    }
   ],
   "source": [
    "from long_form_diarizer import LongFormClusteringDiarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignment_result = {\n",
    "\t\"audio_filepath\": '/usr/src/app/mono_output.wav',\n",
    "    \"text\": \"Ah, now Rich, would you like some pussy? Well, it wasn't on my mind right now. It is now. Pussy energy drink. What flavor is it? Flavor. Dream it. Yeah, moving on. And I'd like to introduce something for which at first I thought I'm going to struggle to find a motoring application because what it is is this. This machine is controlled by your iPhone, right? With an app, and it flies up in the air, and there's a camera on it.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'diarizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Suppose you have a normal config, plus you want to do\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# chunk-based approach for large audio with\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# chunk_cluster_count=50, embeddings_per_chunk=10000\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m diar_model \u001b[38;5;241m=\u001b[39m \u001b[43mLongFormClusteringDiarizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Then call diarize on your input manifest (like normal)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m diar_model\u001b[38;5;241m.\u001b[39mdiarize(alignment_result)\n",
      "File \u001b[0;32m/usr/src/app/inference/long_form_diarizer.py:32\u001b[0m, in \u001b[0;36mLongFormClusteringDiarizer.__init__\u001b[0;34m(self, chunk_cluster_count, embeddings_per_chunk, max_num_speakers, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     18\u001b[0m \t\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     19\u001b[0m \tchunk_cluster_count: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \t\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     24\u001b[0m ):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m\t\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m\tArgs:\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m\t\tchunk_cluster_count (int): Over-clustering target for each chunk\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m\t\t**kwargs: Passed along to the parent ClusteringDiarizer\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\t\"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \t\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_cluster_count \u001b[38;5;241m=\u001b[39m chunk_cluster_count\n\u001b[1;32m     34\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_per_chunk \u001b[38;5;241m=\u001b[39m embeddings_per_chunk\n",
      "File \u001b[0;32m/opt/NeMo/nemo/collections/asr/models/clustering_diarizer.py:92\u001b[0m, in \u001b[0;36mClusteringDiarizer.__init__\u001b[0;34m(self, cfg, speaker_model)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cfg \u001b[38;5;241m=\u001b[39m cfg\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Diarizer set up\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_diarizer_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiarizer\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# init vad model\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_vad_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'diarizer'"
     ]
    }
   ],
   "source": [
    "# Suppose you have a normal config, plus you want to do\n",
    "# chunk-based approach for large audio with\n",
    "# chunk_cluster_count=50, embeddings_per_chunk=10000\n",
    "diar_model = LongFormClusteringDiarizer(cfg = None)\n",
    "\n",
    "# Then call diarize on your input manifest (like normal)\n",
    "diar_model.diarize(alignment_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:26:41 mixins:197] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2025-02-09 07:26:41 mixins:336] Tokenizer SentencePieceTokenizer initialized with 32 tokens\n",
      "[NeMo I 2025-02-09 07:26:41 mixins:336] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-02-09 07:26:41 mixins:336] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-02-09 07:26:41 mixins:336] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-02-09 07:26:41 mixins:336] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-02-09 07:26:41 aggregate_tokenizer:73] Aggregate vocab size: 4128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 07:26:42 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    tarred_audio_filepaths: null\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    shuffle: true\n",
      "    batch_size: null\n",
      "    num_workers: 8\n",
      "    use_lhotse: true\n",
      "    max_duration: 40\n",
      "    pin_memory: true\n",
      "    use_bucketing: false\n",
      "    bucket_duration_bins: null\n",
      "    num_buckets: 1\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    batch_duration: 360\n",
      "    quadratic_duration: 15\n",
      "    bucket_buffer_size: 20000\n",
      "    shuffle_buffer_size: 10000\n",
      "    \n",
      "[NeMo W 2025-02-09 07:26:42 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 0\n",
      "    pin_memory: true\n",
      "    tarred_audio_filepaths: null\n",
      "    use_lhotse: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: false\n",
      "    \n",
      "[NeMo W 2025-02-09 07:26:42 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 0\n",
      "    pin_memory: true\n",
      "    tarred_audio_filepaths: null\n",
      "    use_lhotse: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:26:42 features:305] PADDING: 0\n",
      "[NeMo I 2025-02-09 07:26:53 save_restore_connector:272] Model EncDecMultiTaskModel was successfully restored from /root/.cache/huggingface/hub/models--nvidia--canary-1b/snapshots/dd32c0c709e2bfc79f583e16b9df4b3a160f7e86/canary-1b.nemo.\n",
      "[NeMo I 2025-02-09 07:26:53 aed_multitask_models:260] Changed decoding strategy to \n",
      "    strategy: beam\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: null\n",
      "    compute_langs: false\n",
      "    beam:\n",
      "      beam_size: 1\n",
      "      search_type: default\n",
      "      len_pen: 1.0\n",
      "      max_generation_delta: 20\n",
      "      return_best_hypothesis: true\n",
      "      preserve_alignments: false\n",
      "    temperature: 1.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Suppose you have a diar_infer_meeting.yaml config with multi-scale settings.\n",
    "my_diarizer = LongFormClusteringDiarizer(\n",
    "    diar_config_path=\"diar_infer_meeting.yaml\", \n",
    "    output_dir=\"long_form_output\",\n",
    "    oracle_vad=False,  # or True if you have a ground truth RTTM\n",
    "    chunk_cluster_count=50, \n",
    "    embeddings_per_chunk=10000\n",
    ")\n",
    "\n",
    "audio_file = \"my_long_audio.wav\"  # e.g. 2 hour meeting\n",
    "final_rttm = my_diarizer.diarize(audio_file)\n",
    "print(\"Final RTTM at:\", final_rttm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
