{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ[\"NEMO_CACHE_DIR\"] = \"/your/desired/path\"\n",
    "sys.path.insert(0, '/usr/src/app/inference')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "logging.getLogger(\"nemo_logger\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0209 07:26:35.806730 140105438622848 zarr.py:57] `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).\n"
     ]
    }
   ],
   "source": [
    "from canary_transcriber import CanaryTranscriber\n",
    "from force_aligner import ForceAligner\n",
    "from diarizer import Diarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:26:41 mixins:197] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2025-02-09 07:26:41 mixins:336] Tokenizer SentencePieceTokenizer initialized with 32 tokens\n",
      "[NeMo I 2025-02-09 07:26:41 mixins:336] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-02-09 07:26:41 mixins:336] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-02-09 07:26:41 mixins:336] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-02-09 07:26:41 mixins:336] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-02-09 07:26:41 aggregate_tokenizer:73] Aggregate vocab size: 4128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 07:26:42 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    tarred_audio_filepaths: null\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    shuffle: true\n",
      "    batch_size: null\n",
      "    num_workers: 8\n",
      "    use_lhotse: true\n",
      "    max_duration: 40\n",
      "    pin_memory: true\n",
      "    use_bucketing: false\n",
      "    bucket_duration_bins: null\n",
      "    num_buckets: 1\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    batch_duration: 360\n",
      "    quadratic_duration: 15\n",
      "    bucket_buffer_size: 20000\n",
      "    shuffle_buffer_size: 10000\n",
      "    \n",
      "[NeMo W 2025-02-09 07:26:42 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 0\n",
      "    pin_memory: true\n",
      "    tarred_audio_filepaths: null\n",
      "    use_lhotse: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: false\n",
      "    \n",
      "[NeMo W 2025-02-09 07:26:42 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 0\n",
      "    pin_memory: true\n",
      "    tarred_audio_filepaths: null\n",
      "    use_lhotse: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:26:42 features:305] PADDING: 0\n",
      "[NeMo I 2025-02-09 07:26:53 save_restore_connector:272] Model EncDecMultiTaskModel was successfully restored from /root/.cache/huggingface/hub/models--nvidia--canary-1b/snapshots/dd32c0c709e2bfc79f583e16b9df4b3a160f7e86/canary-1b.nemo.\n",
      "[NeMo I 2025-02-09 07:26:53 aed_multitask_models:260] Changed decoding strategy to \n",
      "    strategy: beam\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: null\n",
      "    compute_langs: false\n",
      "    beam:\n",
      "      beam_size: 1\n",
      "      search_type: default\n",
      "      len_pen: 1.0\n",
      "      max_generation_delta: 20\n",
      "      return_best_hypothesis: true\n",
      "      preserve_alignments: false\n",
      "    temperature: 1.0\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "transcriber = CanaryTranscriber(model_name='nvidia/canary-1b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "force_aligner = ForceAligner(model_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def split_audio(audio_filepath, chunk_duration_sec=600):\n",
    "\t\"\"\"\n",
    "\tSplits the audio into chunks of up to `chunk_duration_sec`.\n",
    "\tReturns a list of tuples (chunk_file_path, chunk_duration).\n",
    "\n",
    "\tWe use pydub for splitting. Each chunk is saved as a temporary .wav.\n",
    "\t\"\"\"\n",
    "\taudio_seg = AudioSegment.from_file(audio_filepath)\n",
    "\ttotal_ms = len(audio_seg)\n",
    "\tchunk_ms = chunk_duration_sec * 1000\n",
    "\n",
    "\tchunks = []\n",
    "\tstart_ms = 0\n",
    "\tidx = 0\n",
    "\n",
    "\twhile start_ms < total_ms:\n",
    "\t\tend_ms = min(start_ms + chunk_ms, total_ms)\n",
    "\t\tchunk = audio_seg[start_ms:end_ms]\n",
    "\t\tchunk_duration = (end_ms - start_ms) / 1000.0\n",
    "\n",
    "\t\tchunk_path = f\"{audio_filepath}_chunk_{idx}.wav\"\n",
    "\t\tchunk.export(chunk_path, format=\"wav\")\n",
    "\t\tchunks.append((chunk_path, chunk_duration))\n",
    "\n",
    "\t\tstart_ms += chunk_ms\n",
    "\t\tidx += 1\n",
    "\n",
    "\treturn chunks\n",
    "\n",
    "def parse_ctm(ctm_file):\n",
    "\titems = []\n",
    "\twith open(ctm_file, \"r\", encoding=\"utf-8\") as f:\n",
    "\t\tfor line in f:\n",
    "\t\t\tparts = line.strip().split()\n",
    "\t\t\tif len(parts) < 5:\n",
    "\t\t\t\tcontinue\n",
    "\t\t\tstart = float(parts[2])\n",
    "\t\t\tdur = float(parts[3])\n",
    "\t\t\ttxt = parts[4]\n",
    "\t\t\titems.append({\n",
    "\t\t\t\t\"start\": round(start, 3),\n",
    "\t\t\t\t\"duration\": round(dur, 3),\n",
    "\t\t\t\t\"end\": round(start + dur, 3),\n",
    "\t\t\t\t\"text\": txt\n",
    "\t\t\t})\n",
    "\treturn items\n",
    "\n",
    "\n",
    "def parse_alignment(alignment_result):\n",
    "\t\"\"\"\n",
    "\tReuses your standard CTM parsing logic, returning a dict with\n",
    "\ttext, words, tokens, segments.\n",
    "\t\"\"\"\n",
    "\talignment_data = {\n",
    "\t\t\"text\": alignment_result.get(\"text\", \"\"),\n",
    "\t\t\"words\": [],\n",
    "\t\t\"tokens\": [],\n",
    "\t\t\"segments\": []\n",
    "\t}\n",
    "\tw_ctm = alignment_result.get(\"words_level_ctm_filepath\")\n",
    "\tt_ctm = alignment_result.get(\"tokens_level_ctm_filepath\")\n",
    "\ts_ctm = alignment_result.get(\"segments_level_ctm_filepath\")\n",
    "\n",
    "\tif w_ctm and os.path.exists(w_ctm):\n",
    "\t\talignment_data[\"words\"] = parse_ctm(w_ctm)\n",
    "\tif t_ctm and os.path.exists(t_ctm):\n",
    "\t\talignment_data[\"tokens\"] = parse_ctm(t_ctm)\n",
    "\tif s_ctm and os.path.exists(s_ctm):\n",
    "\t\talignment_data[\"segments\"] = parse_ctm(s_ctm)\n",
    "\treturn alignment_data\n",
    "\n",
    "def shift_alignment(alignment_data, offset_sec):\n",
    "\t\"\"\"\n",
    "\tShifts the start/end times in alignment_data by offset_sec, in place.\n",
    "\tThis is useful when concatenating chunk alignments into a single timeline.\n",
    "\t\"\"\"\n",
    "\tfor item in alignment_data[\"words\"]:\n",
    "\t\titem[\"start\"] += offset_sec\n",
    "\t\titem[\"end\"] += offset_sec\n",
    "\tfor item in alignment_data[\"tokens\"]:\n",
    "\t\titem[\"start\"] += offset_sec\n",
    "\t\titem[\"end\"] += offset_sec\n",
    "\tfor item in alignment_data[\"segments\"]:\n",
    "\t\titem[\"start\"] += offset_sec\n",
    "\t\titem[\"end\"] += offset_sec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:01,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:26:55 align:159] Hydra config: pretrained_name: stt_en_fastconformer_hybrid_large_pc\n",
      "    model_path: null\n",
      "    manifest_filepath: /tmp/nfa_08jf7ip6/ec50fe5d-2596-47c3-93bf-33d40f5bdf91_manifest.json\n",
      "    output_dir: /tmp/nfa_08jf7ip6/nfa_output\n",
      "    align_using_pred_text: false\n",
      "    transcribe_device: null\n",
      "    viterbi_device: null\n",
      "    batch_size: 1\n",
      "    use_local_attention: true\n",
      "    additional_segment_grouping_separator: '|'\n",
      "    audio_filepath_parts_in_utt_id: 1\n",
      "    use_buffered_chunked_streaming: false\n",
      "    chunk_len_in_secs: 1.6\n",
      "    total_buffer_in_secs: 4.0\n",
      "    chunk_batch_size: 32\n",
      "    simulate_cache_aware_streaming: false\n",
      "    save_output_file_formats:\n",
      "    - ctm\n",
      "    ctm_file_config:\n",
      "      remove_blank_tokens: false\n",
      "      minimum_timestamp_duration: 0.0\n",
      "    ass_file_config:\n",
      "      fontsize: 20\n",
      "      vertical_alignment: center\n",
      "      resegment_text_to_fill_space: false\n",
      "      max_lines_per_segment: 2\n",
      "      text_already_spoken_rgb:\n",
      "      - 49\n",
      "      - 46\n",
      "      - 61\n",
      "      text_being_spoken_rgb:\n",
      "      - 57\n",
      "      - 171\n",
      "      - 9\n",
      "      text_not_yet_spoken_rgb:\n",
      "      - 194\n",
      "      - 193\n",
      "      - 199\n",
      "    \n",
      "[NeMo I 2025-02-09 07:26:55 align:228] Device to be used for transcription step (`transcribe_device`) is cuda\n",
      "[NeMo I 2025-02-09 07:26:55 align:234] Device to be used for viterbi step (`viterbi_device`) is cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2025-02-09 07:26:55 align:237] One or both of transcribe_device and viterbi_device are GPUs. If you run into OOM errors it may help to change both devices to be the CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:26:55 cloud:58] Found existing object /your/desired/path/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2025-02-09 07:26:55 cloud:64] Re-using file from: /your/desired/path/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo\n",
      "[NeMo I 2025-02-09 07:26:55 common:826] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2025-02-09 07:26:56 mixins:173] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 07:26:58 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: false\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 1.0\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20\n",
      "    min_duration: 0.1\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-02-09 07:26:58 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: fisher_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: europarl_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: librispeech_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mcv11_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: nsc1_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: spgi_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: voxpopuli_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mls_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    max_duration: 20\n",
      "    \n",
      "[NeMo W 2025-02-09 07:26:58 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:26:58 features:305] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 07:26:58 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:26:58 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 07:26:58 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 07:26:59 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 07:26:59 save_restore_connector:272] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /your/desired/path/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2025-02-09 07:26:59 hybrid_rnnt_ctc_bpe_models:464] No `decoding_cfg` passed when changing decoding strategy, using internal config\n",
      "[NeMo I 2025-02-09 07:26:59 hybrid_rnnt_ctc_bpe_models:488] Changed decoding strategy of the CTC decoder to \n",
      "    strategy: greedy\n",
      "    preserve_alignments: null\n",
      "    compute_timestamps: null\n",
      "    word_seperator: ' '\n",
      "    ctc_timestamp_type: all\n",
      "    batch_dim_index: 0\n",
      "    greedy:\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "      return_best_hypothesis: true\n",
      "      beam_alpha: 1.0\n",
      "      beam_beta: 0.0\n",
      "      kenlm_path: null\n",
      "      flashlight_cfg:\n",
      "        lexicon_path: null\n",
      "        boost_path: null\n",
      "        beam_size_token: 16\n",
      "        beam_threshold: 20.0\n",
      "        unk_weight: -.inf\n",
      "        sil_weight: 0.0\n",
      "      pyctcdecode_cfg:\n",
      "        beam_prune_logp: -10.0\n",
      "        token_min_logp: -5.0\n",
      "        prune_history: false\n",
      "        hotwords: null\n",
      "        hotword_weight: 10.0\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      tdt_include_duration: false\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2025-02-09 07:26:59 align:250] Flag use_local_attention is set to True => will try to use local attention for model if it allows it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2025-02-09 07:27:00 ctc_greedy_decoding:168] CTC decoding strategy 'greedy' is slower than 'greedy_batch', which implements the same exact interface. Consider changing your strategy to 'greedy_batch' for a free performance improvement.\n",
      "Transcribing: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:00 data_prep:822] Calculated that the model downsample factor is 8 and therefore the ASR model output timestep duration is 0.08 -- will use this for all batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcribing: 1it [00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:01 align:159] Hydra config: pretrained_name: stt_en_fastconformer_hybrid_large_pc\n",
      "    model_path: null\n",
      "    manifest_filepath: /tmp/nfa_j0myud9p/1b155a00-551f-4070-a14d-c16368944456_manifest.json\n",
      "    output_dir: /tmp/nfa_j0myud9p/nfa_output\n",
      "    align_using_pred_text: false\n",
      "    transcribe_device: null\n",
      "    viterbi_device: null\n",
      "    batch_size: 1\n",
      "    use_local_attention: true\n",
      "    additional_segment_grouping_separator: '|'\n",
      "    audio_filepath_parts_in_utt_id: 1\n",
      "    use_buffered_chunked_streaming: false\n",
      "    chunk_len_in_secs: 1.6\n",
      "    total_buffer_in_secs: 4.0\n",
      "    chunk_batch_size: 32\n",
      "    simulate_cache_aware_streaming: false\n",
      "    save_output_file_formats:\n",
      "    - ctm\n",
      "    ctm_file_config:\n",
      "      remove_blank_tokens: false\n",
      "      minimum_timestamp_duration: 0.0\n",
      "    ass_file_config:\n",
      "      fontsize: 20\n",
      "      vertical_alignment: center\n",
      "      resegment_text_to_fill_space: false\n",
      "      max_lines_per_segment: 2\n",
      "      text_already_spoken_rgb:\n",
      "      - 49\n",
      "      - 46\n",
      "      - 61\n",
      "      text_being_spoken_rgb:\n",
      "      - 57\n",
      "      - 171\n",
      "      - 9\n",
      "      text_not_yet_spoken_rgb:\n",
      "      - 194\n",
      "      - 193\n",
      "      - 199\n",
      "    \n",
      "[NeMo I 2025-02-09 07:27:01 align:228] Device to be used for transcription step (`transcribe_device`) is cuda\n",
      "[NeMo I 2025-02-09 07:27:01 align:234] Device to be used for viterbi step (`viterbi_device`) is cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2025-02-09 07:27:01 align:237] One or both of transcribe_device and viterbi_device are GPUs. If you run into OOM errors it may help to change both devices to be the CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:01 cloud:58] Found existing object /your/desired/path/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2025-02-09 07:27:01 cloud:64] Re-using file from: /your/desired/path/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo\n",
      "[NeMo I 2025-02-09 07:27:01 common:826] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2025-02-09 07:27:03 mixins:173] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 07:27:04 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: false\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 1.0\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20\n",
      "    min_duration: 0.1\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-02-09 07:27:04 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: fisher_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: europarl_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: librispeech_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mcv11_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: nsc1_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: spgi_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: voxpopuli_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mls_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    max_duration: 20\n",
      "    \n",
      "[NeMo W 2025-02-09 07:27:04 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:04 features:305] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 07:27:04 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:04 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 07:27:04 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 07:27:05 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 07:27:05 save_restore_connector:272] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /your/desired/path/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2025-02-09 07:27:05 hybrid_rnnt_ctc_bpe_models:464] No `decoding_cfg` passed when changing decoding strategy, using internal config\n",
      "[NeMo I 2025-02-09 07:27:05 hybrid_rnnt_ctc_bpe_models:488] Changed decoding strategy of the CTC decoder to \n",
      "    strategy: greedy\n",
      "    preserve_alignments: null\n",
      "    compute_timestamps: null\n",
      "    word_seperator: ' '\n",
      "    ctc_timestamp_type: all\n",
      "    batch_dim_index: 0\n",
      "    greedy:\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "      return_best_hypothesis: true\n",
      "      beam_alpha: 1.0\n",
      "      beam_beta: 0.0\n",
      "      kenlm_path: null\n",
      "      flashlight_cfg:\n",
      "        lexicon_path: null\n",
      "        boost_path: null\n",
      "        beam_size_token: 16\n",
      "        beam_threshold: 20.0\n",
      "        unk_weight: -.inf\n",
      "        sil_weight: 0.0\n",
      "      pyctcdecode_cfg:\n",
      "        beam_prune_logp: -10.0\n",
      "        token_min_logp: -5.0\n",
      "        prune_history: false\n",
      "        hotwords: null\n",
      "        hotword_weight: 10.0\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      tdt_include_duration: false\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2025-02-09 07:27:05 align:250] Flag use_local_attention is set to True => will try to use local attention for model if it allows it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|██████████| 1/1 [00:00<00:00,  9.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:05 data_prep:822] Calculated that the model downsample factor is 8 and therefore the ASR model output timestep duration is 0.08 -- will use this for all batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcribing: 1it [00:01,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:07 align:159] Hydra config: pretrained_name: stt_en_fastconformer_hybrid_large_pc\n",
      "    model_path: null\n",
      "    manifest_filepath: /tmp/nfa_7g4vb_v8/a8b0a672-ef59-432a-a22e-928daa4f8cc2_manifest.json\n",
      "    output_dir: /tmp/nfa_7g4vb_v8/nfa_output\n",
      "    align_using_pred_text: false\n",
      "    transcribe_device: null\n",
      "    viterbi_device: null\n",
      "    batch_size: 1\n",
      "    use_local_attention: true\n",
      "    additional_segment_grouping_separator: '|'\n",
      "    audio_filepath_parts_in_utt_id: 1\n",
      "    use_buffered_chunked_streaming: false\n",
      "    chunk_len_in_secs: 1.6\n",
      "    total_buffer_in_secs: 4.0\n",
      "    chunk_batch_size: 32\n",
      "    simulate_cache_aware_streaming: false\n",
      "    save_output_file_formats:\n",
      "    - ctm\n",
      "    ctm_file_config:\n",
      "      remove_blank_tokens: false\n",
      "      minimum_timestamp_duration: 0.0\n",
      "    ass_file_config:\n",
      "      fontsize: 20\n",
      "      vertical_alignment: center\n",
      "      resegment_text_to_fill_space: false\n",
      "      max_lines_per_segment: 2\n",
      "      text_already_spoken_rgb:\n",
      "      - 49\n",
      "      - 46\n",
      "      - 61\n",
      "      text_being_spoken_rgb:\n",
      "      - 57\n",
      "      - 171\n",
      "      - 9\n",
      "      text_not_yet_spoken_rgb:\n",
      "      - 194\n",
      "      - 193\n",
      "      - 199\n",
      "    \n",
      "[NeMo I 2025-02-09 07:27:07 align:228] Device to be used for transcription step (`transcribe_device`) is cuda\n",
      "[NeMo I 2025-02-09 07:27:07 align:234] Device to be used for viterbi step (`viterbi_device`) is cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2025-02-09 07:27:07 align:237] One or both of transcribe_device and viterbi_device are GPUs. If you run into OOM errors it may help to change both devices to be the CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:07 cloud:58] Found existing object /your/desired/path/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2025-02-09 07:27:07 cloud:64] Re-using file from: /your/desired/path/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo\n",
      "[NeMo I 2025-02-09 07:27:07 common:826] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2025-02-09 07:27:08 mixins:173] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 07:27:09 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: false\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 1.0\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20\n",
      "    min_duration: 0.1\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-02-09 07:27:09 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: fisher_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: europarl_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: librispeech_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mcv11_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: nsc1_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: spgi_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: voxpopuli_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mls_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    max_duration: 20\n",
      "    \n",
      "[NeMo W 2025-02-09 07:27:09 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:09 features:305] PADDING: 0\n",
      "[NeMo I 2025-02-09 07:27:10 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 07:27:10 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 07:27:10 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 07:27:11 save_restore_connector:272] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /your/desired/path/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2025-02-09 07:27:11 hybrid_rnnt_ctc_bpe_models:464] No `decoding_cfg` passed when changing decoding strategy, using internal config\n",
      "[NeMo I 2025-02-09 07:27:11 hybrid_rnnt_ctc_bpe_models:488] Changed decoding strategy of the CTC decoder to \n",
      "    strategy: greedy\n",
      "    preserve_alignments: null\n",
      "    compute_timestamps: null\n",
      "    word_seperator: ' '\n",
      "    ctc_timestamp_type: all\n",
      "    batch_dim_index: 0\n",
      "    greedy:\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "      return_best_hypothesis: true\n",
      "      beam_alpha: 1.0\n",
      "      beam_beta: 0.0\n",
      "      kenlm_path: null\n",
      "      flashlight_cfg:\n",
      "        lexicon_path: null\n",
      "        boost_path: null\n",
      "        beam_size_token: 16\n",
      "        beam_threshold: 20.0\n",
      "        unk_weight: -.inf\n",
      "        sil_weight: 0.0\n",
      "      pyctcdecode_cfg:\n",
      "        beam_prune_logp: -10.0\n",
      "        token_min_logp: -5.0\n",
      "        prune_history: false\n",
      "        hotwords: null\n",
      "        hotword_weight: 10.0\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      tdt_include_duration: false\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2025-02-09 07:27:11 align:250] Flag use_local_attention is set to True => will try to use local attention for model if it allows it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 11.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:11 data_prep:822] Calculated that the model downsample factor is 8 and therefore the ASR model output timestep duration is 0.08 -- will use this for all batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcribing: 1it [00:01,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:13 align:159] Hydra config: pretrained_name: stt_en_fastconformer_hybrid_large_pc\n",
      "    model_path: null\n",
      "    manifest_filepath: /tmp/nfa__rwbkn2d/a2a0396d-b141-425d-beff-d27d73550353_manifest.json\n",
      "    output_dir: /tmp/nfa__rwbkn2d/nfa_output\n",
      "    align_using_pred_text: false\n",
      "    transcribe_device: null\n",
      "    viterbi_device: null\n",
      "    batch_size: 1\n",
      "    use_local_attention: true\n",
      "    additional_segment_grouping_separator: '|'\n",
      "    audio_filepath_parts_in_utt_id: 1\n",
      "    use_buffered_chunked_streaming: false\n",
      "    chunk_len_in_secs: 1.6\n",
      "    total_buffer_in_secs: 4.0\n",
      "    chunk_batch_size: 32\n",
      "    simulate_cache_aware_streaming: false\n",
      "    save_output_file_formats:\n",
      "    - ctm\n",
      "    ctm_file_config:\n",
      "      remove_blank_tokens: false\n",
      "      minimum_timestamp_duration: 0.0\n",
      "    ass_file_config:\n",
      "      fontsize: 20\n",
      "      vertical_alignment: center\n",
      "      resegment_text_to_fill_space: false\n",
      "      max_lines_per_segment: 2\n",
      "      text_already_spoken_rgb:\n",
      "      - 49\n",
      "      - 46\n",
      "      - 61\n",
      "      text_being_spoken_rgb:\n",
      "      - 57\n",
      "      - 171\n",
      "      - 9\n",
      "      text_not_yet_spoken_rgb:\n",
      "      - 194\n",
      "      - 193\n",
      "      - 199\n",
      "    \n",
      "[NeMo I 2025-02-09 07:27:13 align:228] Device to be used for transcription step (`transcribe_device`) is cuda\n",
      "[NeMo I 2025-02-09 07:27:13 align:234] Device to be used for viterbi step (`viterbi_device`) is cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2025-02-09 07:27:13 align:237] One or both of transcribe_device and viterbi_device are GPUs. If you run into OOM errors it may help to change both devices to be the CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:13 cloud:58] Found existing object /your/desired/path/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2025-02-09 07:27:13 cloud:64] Re-using file from: /your/desired/path/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo\n",
      "[NeMo I 2025-02-09 07:27:13 common:826] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2025-02-09 07:27:14 mixins:173] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 07:27:15 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: false\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 1.0\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20\n",
      "    min_duration: 0.1\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-02-09 07:27:15 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: fisher_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: europarl_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: librispeech_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mcv11_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: nsc1_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: spgi_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: voxpopuli_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mls_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    max_duration: 20\n",
      "    \n",
      "[NeMo W 2025-02-09 07:27:15 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:15 features:305] PADDING: 0\n",
      "[NeMo I 2025-02-09 07:27:16 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 07:27:16 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 07:27:16 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 07:27:16 save_restore_connector:272] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /your/desired/path/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2025-02-09 07:27:16 hybrid_rnnt_ctc_bpe_models:464] No `decoding_cfg` passed when changing decoding strategy, using internal config\n",
      "[NeMo I 2025-02-09 07:27:16 hybrid_rnnt_ctc_bpe_models:488] Changed decoding strategy of the CTC decoder to \n",
      "    strategy: greedy\n",
      "    preserve_alignments: null\n",
      "    compute_timestamps: null\n",
      "    word_seperator: ' '\n",
      "    ctc_timestamp_type: all\n",
      "    batch_dim_index: 0\n",
      "    greedy:\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "      return_best_hypothesis: true\n",
      "      beam_alpha: 1.0\n",
      "      beam_beta: 0.0\n",
      "      kenlm_path: null\n",
      "      flashlight_cfg:\n",
      "        lexicon_path: null\n",
      "        boost_path: null\n",
      "        beam_size_token: 16\n",
      "        beam_threshold: 20.0\n",
      "        unk_weight: -.inf\n",
      "        sil_weight: 0.0\n",
      "      pyctcdecode_cfg:\n",
      "        beam_prune_logp: -10.0\n",
      "        token_min_logp: -5.0\n",
      "        prune_history: false\n",
      "        hotwords: null\n",
      "        hotword_weight: 10.0\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      tdt_include_duration: false\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2025-02-09 07:27:16 align:250] Flag use_local_attention is set to True => will try to use local attention for model if it allows it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:27:17 data_prep:822] Calculated that the model downsample factor is 8 and therefore the ASR model output timestep duration is 0.08 -- will use this for all batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "audio_filepath = '/usr/src/app/mono_output.wav'\n",
    "chunk_duration_sec = 10\n",
    "\n",
    "chunk_paths = split_audio(audio_filepath, chunk_duration_sec)\n",
    "all_words = []\n",
    "all_tokens = []\n",
    "all_segments = []\n",
    "offset_sec = 0.0\n",
    "final_transcript_parts = []\n",
    "\n",
    "for chunk_file, chunk_dur in chunk_paths:\n",
    "\t# 1. Transcription on chunk\n",
    "\tchunk_text = transcriber.transcribe(chunk_file)\n",
    "\tfinal_transcript_parts.append(chunk_text)\n",
    "\n",
    "\t# 2. Force align chunk\n",
    "\tchunk_alignment_result = force_aligner.align(chunk_file, chunk_text)\n",
    "\t# Parse alignment into memory\n",
    "\tchunk_alignment_data = parse_alignment(chunk_alignment_result)\n",
    "\n",
    "\t# Adjust times by offset\n",
    "\tshift_alignment(chunk_alignment_data, offset_sec)\n",
    "\n",
    "\t# Merge into global arrays\n",
    "\tall_words.extend(chunk_alignment_data[\"words\"])\n",
    "\tall_tokens.extend(chunk_alignment_data[\"tokens\"])\n",
    "\tall_segments.extend(chunk_alignment_data[\"segments\"])\n",
    "\n",
    "\toffset_sec += chunk_dur\n",
    "\n",
    "\t# Clean up chunk temp file if needed\n",
    "\tos.remove(chunk_file)\n",
    "\n",
    "final_transcript = \" \".join(final_transcript_parts).strip()\n",
    "merged_alignment = {\n",
    "\t\"text\": final_transcript,\n",
    "\t\"words\": all_words,\n",
    "\t\"tokens\": all_tokens,\n",
    "\t\"segments\": all_segments,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"Ah, now Rich, would you like some pussy? Well, it wasn't on my mind right now. It is now. Pussy energy drink. What flavor is it? Flavor. Dream it. Yeah, moving on. And I'd like to introduce something for which at first I thought I'm going to struggle to find a motoring application because what it is is this. This machine is controlled by your iPhone, right? With an app, and it flies up in the air, and there's a camera on it.\", 'words': [{'start': 0.32, 'duration': 0.48, 'end': 0.8, 'text': 'Ah,'}, {'start': 0.88, 'duration': 0.08, 'end': 0.96, 'text': 'now'}, {'start': 1.28, 'duration': 0.56, 'end': 1.84, 'text': 'Rich,'}, {'start': 1.92, 'duration': 0.08, 'end': 2.0, 'text': 'would'}, {'start': 2.32, 'duration': 0.08, 'end': 2.4, 'text': 'you'}, {'start': 2.56, 'duration': 0.08, 'end': 2.64, 'text': 'like'}, {'start': 2.8, 'duration': 0.08, 'end': 2.88, 'text': 'some'}, {'start': 3.04, 'duration': 2.32, 'end': 5.36, 'text': 'pussy?'}, {'start': 5.92, 'duration': 0.32, 'end': 6.24, 'text': 'Well,'}, {'start': 6.24, 'duration': 0.08, 'end': 6.32, 'text': 'it'}, {'start': 6.4, 'duration': 0.32, 'end': 6.72, 'text': \"wasn't\"}, {'start': 6.72, 'duration': 0.08, 'end': 6.8, 'text': 'on'}, {'start': 6.88, 'duration': 0.08, 'end': 6.96, 'text': 'my'}, {'start': 7.04, 'duration': 0.08, 'end': 7.12, 'text': 'mind'}, {'start': 7.44, 'duration': 0.08, 'end': 7.52, 'text': 'right'}, {'start': 7.68, 'duration': 0.24, 'end': 7.92, 'text': 'now.'}, {'start': 8.08, 'duration': 0.08, 'end': 8.16, 'text': 'It'}, {'start': 8.24, 'duration': 0.08, 'end': 8.32, 'text': 'is'}, {'start': 8.48, 'duration': 0.32, 'end': 8.8, 'text': 'now.'}, {'start': 10.08, 'duration': 0.48, 'end': 10.56, 'text': 'Pussy'}, {'start': 10.64, 'duration': 0.4, 'end': 11.04, 'text': 'energy'}, {'start': 11.04, 'duration': 1.52, 'end': 12.56, 'text': 'drink.'}, {'start': 14.32, 'duration': 0.08, 'end': 14.4, 'text': 'What'}, {'start': 14.559999999999999, 'duration': 0.4, 'end': 14.96, 'text': 'flavor'}, {'start': 15.04, 'duration': 0.08, 'end': 15.120000000000001, 'text': 'is'}, {'start': 15.2, 'duration': 0.32, 'end': 15.52, 'text': 'it?'}, {'start': 15.68, 'duration': 2.24, 'end': 17.92, 'text': 'Flavor.'}, {'start': 20.0, 'duration': 1.28, 'end': 21.28, 'text': 'Dream'}, {'start': 21.36, 'duration': 0.32, 'end': 21.68, 'text': 'it.'}, {'start': 21.76, 'duration': 0.24, 'end': 22.0, 'text': 'Yeah,'}, {'start': 22.08, 'duration': 0.32, 'end': 22.4, 'text': 'moving'}, {'start': 22.4, 'duration': 0.32, 'end': 22.72, 'text': 'on.'}, {'start': 22.72, 'duration': 0.08, 'end': 22.8, 'text': 'And'}, {'start': 22.88, 'duration': 0.24, 'end': 23.12, 'text': \"I'd\"}, {'start': 23.12, 'duration': 0.16, 'end': 23.28, 'text': 'like'}, {'start': 23.28, 'duration': 0.08, 'end': 23.36, 'text': 'to'}, {'start': 23.36, 'duration': 0.48, 'end': 23.84, 'text': 'introduce'}, {'start': 23.84, 'duration': 0.08, 'end': 23.92, 'text': 'something'}, {'start': 24.08, 'duration': 0.08, 'end': 24.16, 'text': 'for'}, {'start': 24.16, 'duration': 0.08, 'end': 24.240000000000002, 'text': 'which'}, {'start': 24.4, 'duration': 0.08, 'end': 24.48, 'text': 'at'}, {'start': 24.56, 'duration': 0.08, 'end': 24.64, 'text': 'first'}, {'start': 24.8, 'duration': 0.08, 'end': 24.88, 'text': 'I'}, {'start': 24.88, 'duration': 0.08, 'end': 24.96, 'text': 'thought'}, {'start': 25.04, 'duration': 0.24, 'end': 25.28, 'text': \"I'm\"}, {'start': 25.28, 'duration': 0.08, 'end': 25.36, 'text': 'going'}, {'start': 25.36, 'duration': 0.08, 'end': 25.44, 'text': 'to'}, {'start': 25.44, 'duration': 0.4, 'end': 25.84, 'text': 'struggle'}, {'start': 25.84, 'duration': 0.08, 'end': 25.92, 'text': 'to'}, {'start': 25.92, 'duration': 0.08, 'end': 26.0, 'text': 'find'}, {'start': 26.0, 'duration': 0.08, 'end': 26.08, 'text': 'a'}, {'start': 26.08, 'duration': 0.32, 'end': 26.4, 'text': 'motoring'}, {'start': 26.48, 'duration': 0.4, 'end': 26.88, 'text': 'application'}, {'start': 27.04, 'duration': 0.08, 'end': 27.12, 'text': 'because'}, {'start': 27.759999999999998, 'duration': 0.08, 'end': 27.84, 'text': 'what'}, {'start': 27.92, 'duration': 0.08, 'end': 28.0, 'text': 'it'}, {'start': 28.16, 'duration': 0.08, 'end': 28.240000000000002, 'text': 'is'}, {'start': 28.72, 'duration': 0.08, 'end': 28.8, 'text': 'is'}, {'start': 29.6, 'duration': 0.4, 'end': 30.0, 'text': 'this.'}, {'start': 30.0, 'duration': 0.08, 'end': 30.08, 'text': 'This'}, {'start': 30.32, 'duration': 0.24, 'end': 30.56, 'text': 'machine'}, {'start': 30.56, 'duration': 0.16, 'end': 30.72, 'text': 'is'}, {'start': 30.72, 'duration': 0.32, 'end': 31.04, 'text': 'controlled'}, {'start': 31.04, 'duration': 0.08, 'end': 31.12, 'text': 'by'}, {'start': 31.12, 'duration': 0.08, 'end': 31.2, 'text': 'your'}, {'start': 31.2, 'duration': 0.48, 'end': 31.68, 'text': 'iPhone,'}, {'start': 31.68, 'duration': 0.16, 'end': 31.84, 'text': 'right?'}, {'start': 31.84, 'duration': 0.08, 'end': 31.92, 'text': 'With'}, {'start': 32.0, 'duration': 0.08, 'end': 32.08, 'text': 'an'}, {'start': 32.16, 'duration': 0.4, 'end': 32.56, 'text': 'app,'}, {'start': 32.56, 'duration': 0.08, 'end': 32.64, 'text': 'and'}, {'start': 32.8, 'duration': 0.08, 'end': 32.88, 'text': 'it'}, {'start': 32.96, 'duration': 0.32, 'end': 33.28, 'text': 'flies'}, {'start': 33.44, 'duration': 0.08, 'end': 33.52, 'text': 'up'}, {'start': 33.6, 'duration': 0.08, 'end': 33.68, 'text': 'in'}, {'start': 33.68, 'duration': 0.08, 'end': 33.76, 'text': 'the'}, {'start': 33.76, 'duration': 0.24, 'end': 34.0, 'text': 'air,'}, {'start': 34.0, 'duration': 0.08, 'end': 34.08, 'text': 'and'}, {'start': 34.08, 'duration': 0.32, 'end': 34.4, 'text': \"there's\"}, {'start': 34.4, 'duration': 0.08, 'end': 34.480000000000004, 'text': 'a'}, {'start': 34.480000000000004, 'duration': 0.32, 'end': 34.8, 'text': 'camera'}, {'start': 34.8, 'duration': 0.08, 'end': 34.88, 'text': 'on'}, {'start': 34.88, 'duration': 0.32, 'end': 35.2, 'text': 'it.'}], 'tokens': [{'start': 0.0, 'duration': 0.32, 'end': 0.32, 'text': '<b>'}, {'start': 0.32, 'duration': 0.08, 'end': 0.4, 'text': '▁A'}, {'start': 0.4, 'duration': 0.08, 'end': 0.48, 'text': '<b>'}, {'start': 0.48, 'duration': 0.16, 'end': 0.64, 'text': 'h'}, {'start': 0.64, 'duration': 0.08, 'end': 0.72, 'text': '<b>'}, {'start': 0.72, 'duration': 0.08, 'end': 0.8, 'text': ','}, {'start': 0.8, 'duration': 0.08, 'end': 0.88, 'text': '<b>'}, {'start': 0.88, 'duration': 0.08, 'end': 0.96, 'text': '▁now'}, {'start': 0.96, 'duration': 0.32, 'end': 1.28, 'text': '<b>'}, {'start': 1.28, 'duration': 0.08, 'end': 1.36, 'text': '▁Ri'}, {'start': 1.36, 'duration': 0.16, 'end': 1.52, 'text': '<b>'}, {'start': 1.52, 'duration': 0.08, 'end': 1.6, 'text': 'ch'}, {'start': 1.6, 'duration': 0.16, 'end': 1.76, 'text': '<b>'}, {'start': 1.76, 'duration': 0.08, 'end': 1.84, 'text': ','}, {'start': 1.84, 'duration': 0.08, 'end': 1.92, 'text': '<b>'}, {'start': 1.92, 'duration': 0.08, 'end': 2.0, 'text': '▁would'}, {'start': 2.0, 'duration': 0.32, 'end': 2.32, 'text': '<b>'}, {'start': 2.32, 'duration': 0.08, 'end': 2.4, 'text': '▁you'}, {'start': 2.4, 'duration': 0.16, 'end': 2.56, 'text': '<b>'}, {'start': 2.56, 'duration': 0.08, 'end': 2.64, 'text': '▁like'}, {'start': 2.64, 'duration': 0.16, 'end': 2.8, 'text': '<b>'}, {'start': 2.8, 'duration': 0.08, 'end': 2.88, 'text': '▁some'}, {'start': 2.88, 'duration': 0.16, 'end': 3.04, 'text': '<b>'}, {'start': 3.04, 'duration': 0.08, 'end': 3.12, 'text': '▁pu'}, {'start': 3.12, 'duration': 0.08, 'end': 3.2, 'text': 's'}, {'start': 3.2, 'duration': 0.16, 'end': 3.36, 'text': '<b>'}, {'start': 3.36, 'duration': 0.08, 'end': 3.44, 'text': 's'}, {'start': 3.44, 'duration': 0.08, 'end': 3.52, 'text': 'y'}, {'start': 3.52, 'duration': 1.76, 'end': 5.28, 'text': '<b>'}, {'start': 5.28, 'duration': 0.08, 'end': 5.36, 'text': '?'}, {'start': 5.36, 'duration': 0.56, 'end': 5.92, 'text': '<b>'}, {'start': 5.92, 'duration': 0.08, 'end': 6.0, 'text': '▁Well'}, {'start': 6.0, 'duration': 0.16, 'end': 6.16, 'text': '<b>'}, {'start': 6.16, 'duration': 0.08, 'end': 6.24, 'text': ','}, {'start': 6.24, 'duration': 0.08, 'end': 6.32, 'text': '▁it'}, {'start': 6.32, 'duration': 0.08, 'end': 6.4, 'text': '<b>'}, {'start': 6.4, 'duration': 0.08, 'end': 6.48, 'text': '▁was'}, {'start': 6.48, 'duration': 0.08, 'end': 6.56, 'text': 'n'}, {'start': 6.56, 'duration': 0.08, 'end': 6.64, 'text': \"'\"}, {'start': 6.64, 'duration': 0.08, 'end': 6.72, 'text': 't'}, {'start': 6.72, 'duration': 0.08, 'end': 6.8, 'text': '▁on'}, {'start': 6.8, 'duration': 0.08, 'end': 6.88, 'text': '<b>'}, {'start': 6.88, 'duration': 0.08, 'end': 6.96, 'text': '▁my'}, {'start': 6.96, 'duration': 0.08, 'end': 7.04, 'text': '<b>'}, {'start': 7.04, 'duration': 0.08, 'end': 7.12, 'text': '▁mind'}, {'start': 7.12, 'duration': 0.32, 'end': 7.44, 'text': '<b>'}, {'start': 7.44, 'duration': 0.08, 'end': 7.52, 'text': '▁right'}, {'start': 7.52, 'duration': 0.16, 'end': 7.68, 'text': '<b>'}, {'start': 7.68, 'duration': 0.08, 'end': 7.76, 'text': '▁now'}, {'start': 7.76, 'duration': 0.08, 'end': 7.84, 'text': '<b>'}, {'start': 7.84, 'duration': 0.08, 'end': 7.92, 'text': '.'}, {'start': 7.92, 'duration': 0.16, 'end': 8.08, 'text': '<b>'}, {'start': 8.08, 'duration': 0.08, 'end': 8.16, 'text': '▁It'}, {'start': 8.16, 'duration': 0.08, 'end': 8.24, 'text': '<b>'}, {'start': 8.24, 'duration': 0.08, 'end': 8.32, 'text': '▁is'}, {'start': 8.32, 'duration': 0.16, 'end': 8.48, 'text': '<b>'}, {'start': 8.48, 'duration': 0.08, 'end': 8.56, 'text': '▁now'}, {'start': 8.56, 'duration': 0.16, 'end': 8.72, 'text': '<b>'}, {'start': 8.72, 'duration': 0.08, 'end': 8.8, 'text': '.'}, {'start': 8.8, 'duration': 1.28, 'end': 10.08, 'text': '<b>'}, {'start': 10.0, 'duration': 0.08, 'end': 10.08, 'text': '<b>'}, {'start': 10.08, 'duration': 0.08, 'end': 10.16, 'text': '▁P'}, {'start': 10.16, 'duration': 0.08, 'end': 10.24, 'text': '<b>'}, {'start': 10.24, 'duration': 0.08, 'end': 10.32, 'text': 'us'}, {'start': 10.32, 'duration': 0.08, 'end': 10.4, 'text': '<b>'}, {'start': 10.4, 'duration': 0.08, 'end': 10.48, 'text': 's'}, {'start': 10.48, 'duration': 0.08, 'end': 10.56, 'text': 'y'}, {'start': 10.56, 'duration': 0.08, 'end': 10.64, 'text': '<b>'}, {'start': 10.64, 'duration': 0.08, 'end': 10.72, 'text': '▁en'}, {'start': 10.72, 'duration': 0.08, 'end': 10.8, 'text': 'er'}, {'start': 10.8, 'duration': 0.16, 'end': 10.96, 'text': 'g'}, {'start': 10.96, 'duration': 0.08, 'end': 11.04, 'text': 'y'}, {'start': 11.04, 'duration': 0.08, 'end': 11.120000000000001, 'text': '▁dr'}, {'start': 11.120000000000001, 'duration': 0.08, 'end': 11.2, 'text': '<b>'}, {'start': 11.2, 'duration': 0.08, 'end': 11.28, 'text': 'in'}, {'start': 11.28, 'duration': 0.08, 'end': 11.36, 'text': 'k'}, {'start': 11.36, 'duration': 1.12, 'end': 12.48, 'text': '<b>'}, {'start': 12.48, 'duration': 0.08, 'end': 12.56, 'text': '.'}, {'start': 12.56, 'duration': 1.76, 'end': 14.32, 'text': '<b>'}, {'start': 14.32, 'duration': 0.08, 'end': 14.4, 'text': '▁What'}, {'start': 14.4, 'duration': 0.16, 'end': 14.559999999999999, 'text': '<b>'}, {'start': 14.559999999999999, 'duration': 0.08, 'end': 14.64, 'text': '▁fl'}, {'start': 14.64, 'duration': 0.08, 'end': 14.719999999999999, 'text': 'a'}, {'start': 14.719999999999999, 'duration': 0.08, 'end': 14.8, 'text': '<b>'}, {'start': 14.8, 'duration': 0.08, 'end': 14.879999999999999, 'text': 'v'}, {'start': 14.879999999999999, 'duration': 0.08, 'end': 14.96, 'text': 'or'}, {'start': 14.96, 'duration': 0.08, 'end': 15.04, 'text': '<b>'}, {'start': 15.04, 'duration': 0.08, 'end': 15.120000000000001, 'text': '▁is'}, {'start': 15.120000000000001, 'duration': 0.08, 'end': 15.2, 'text': '<b>'}, {'start': 15.2, 'duration': 0.08, 'end': 15.280000000000001, 'text': '▁it'}, {'start': 15.280000000000001, 'duration': 0.16, 'end': 15.440000000000001, 'text': '<b>'}, {'start': 15.440000000000001, 'duration': 0.08, 'end': 15.52, 'text': '?'}, {'start': 15.52, 'duration': 0.16, 'end': 15.68, 'text': '<b>'}, {'start': 15.68, 'duration': 0.08, 'end': 15.76, 'text': '▁F'}, {'start': 15.76, 'duration': 0.08, 'end': 15.84, 'text': '<b>'}, {'start': 15.84, 'duration': 0.08, 'end': 15.92, 'text': 'la'}, {'start': 15.92, 'duration': 0.16, 'end': 16.08, 'text': '<b>'}, {'start': 16.08, 'duration': 0.08, 'end': 16.16, 'text': 'v'}, {'start': 16.16, 'duration': 0.08, 'end': 16.240000000000002, 'text': '<b>'}, {'start': 16.240000000000002, 'duration': 0.08, 'end': 16.32, 'text': 'or'}, {'start': 16.32, 'duration': 1.52, 'end': 17.84, 'text': '<b>'}, {'start': 17.84, 'duration': 0.08, 'end': 17.92, 'text': '.'}, {'start': 17.92, 'duration': 2.16, 'end': 20.08, 'text': '<b>'}, {'start': 20.0, 'duration': 0.08, 'end': 20.08, 'text': '▁'}, {'start': 20.08, 'duration': 0.88, 'end': 20.96, 'text': '<b>'}, {'start': 20.96, 'duration': 0.08, 'end': 21.04, 'text': 'D'}, {'start': 21.04, 'duration': 0.08, 'end': 21.12, 'text': 're'}, {'start': 21.12, 'duration': 0.08, 'end': 21.2, 'text': '<b>'}, {'start': 21.2, 'duration': 0.08, 'end': 21.28, 'text': 'am'}, {'start': 21.28, 'duration': 0.08, 'end': 21.36, 'text': '<b>'}, {'start': 21.36, 'duration': 0.08, 'end': 21.44, 'text': '▁it'}, {'start': 21.44, 'duration': 0.16, 'end': 21.6, 'text': '<b>'}, {'start': 21.6, 'duration': 0.08, 'end': 21.68, 'text': '.'}, {'start': 21.68, 'duration': 0.08, 'end': 21.76, 'text': '<b>'}, {'start': 21.76, 'duration': 0.08, 'end': 21.84, 'text': '▁Yeah'}, {'start': 21.84, 'duration': 0.08, 'end': 21.92, 'text': '<b>'}, {'start': 21.92, 'duration': 0.08, 'end': 22.0, 'text': ','}, {'start': 22.0, 'duration': 0.08, 'end': 22.08, 'text': '<b>'}, {'start': 22.08, 'duration': 0.08, 'end': 22.16, 'text': '▁mo'}, {'start': 22.16, 'duration': 0.16, 'end': 22.32, 'text': '<b>'}, {'start': 22.32, 'duration': 0.08, 'end': 22.4, 'text': 'ving'}, {'start': 22.4, 'duration': 0.08, 'end': 22.48, 'text': '▁on'}, {'start': 22.48, 'duration': 0.16, 'end': 22.64, 'text': '<b>'}, {'start': 22.64, 'duration': 0.08, 'end': 22.72, 'text': '.'}, {'start': 22.72, 'duration': 0.08, 'end': 22.8, 'text': '▁And'}, {'start': 22.8, 'duration': 0.08, 'end': 22.88, 'text': '<b>'}, {'start': 22.88, 'duration': 0.08, 'end': 22.96, 'text': '▁I'}, {'start': 22.96, 'duration': 0.08, 'end': 23.04, 'text': \"'\"}, {'start': 23.04, 'duration': 0.08, 'end': 23.12, 'text': 'd'}, {'start': 23.12, 'duration': 0.16, 'end': 23.28, 'text': '▁like'}, {'start': 23.28, 'duration': 0.08, 'end': 23.36, 'text': '▁to'}, {'start': 23.36, 'duration': 0.08, 'end': 23.44, 'text': '▁in'}, {'start': 23.44, 'duration': 0.08, 'end': 23.52, 'text': 't'}, {'start': 23.52, 'duration': 0.16, 'end': 23.68, 'text': 'ro'}, {'start': 23.68, 'duration': 0.08, 'end': 23.759999999999998, 'text': 'duc'}, {'start': 23.759999999999998, 'duration': 0.08, 'end': 23.84, 'text': 'e'}, {'start': 23.84, 'duration': 0.08, 'end': 23.92, 'text': '▁something'}, {'start': 23.92, 'duration': 0.16, 'end': 24.08, 'text': '<b>'}, {'start': 24.08, 'duration': 0.08, 'end': 24.16, 'text': '▁for'}, {'start': 24.16, 'duration': 0.08, 'end': 24.240000000000002, 'text': '▁which'}, {'start': 24.240000000000002, 'duration': 0.16, 'end': 24.4, 'text': '<b>'}, {'start': 24.4, 'duration': 0.08, 'end': 24.48, 'text': '▁at'}, {'start': 24.48, 'duration': 0.08, 'end': 24.56, 'text': '<b>'}, {'start': 24.56, 'duration': 0.08, 'end': 24.64, 'text': '▁first'}, {'start': 24.64, 'duration': 0.16, 'end': 24.8, 'text': '<b>'}, {'start': 24.8, 'duration': 0.08, 'end': 24.88, 'text': '▁I'}, {'start': 24.88, 'duration': 0.08, 'end': 24.96, 'text': '▁thought'}, {'start': 24.96, 'duration': 0.08, 'end': 25.04, 'text': '<b>'}, {'start': 25.04, 'duration': 0.08, 'end': 25.12, 'text': '▁I'}, {'start': 25.12, 'duration': 0.08, 'end': 25.2, 'text': \"'\"}, {'start': 25.2, 'duration': 0.08, 'end': 25.28, 'text': 'm'}, {'start': 25.28, 'duration': 0.08, 'end': 25.36, 'text': '▁going'}, {'start': 25.36, 'duration': 0.08, 'end': 25.44, 'text': '▁to'}, {'start': 25.44, 'duration': 0.08, 'end': 25.52, 'text': '▁str'}, {'start': 25.52, 'duration': 0.08, 'end': 25.6, 'text': 'u'}, {'start': 25.6, 'duration': 0.16, 'end': 25.759999999999998, 'text': 'gg'}, {'start': 25.759999999999998, 'duration': 0.08, 'end': 25.84, 'text': 'le'}, {'start': 25.84, 'duration': 0.08, 'end': 25.92, 'text': '▁to'}, {'start': 25.92, 'duration': 0.08, 'end': 26.0, 'text': '▁find'}, {'start': 26.0, 'duration': 0.08, 'end': 26.08, 'text': '▁a'}, {'start': 26.08, 'duration': 0.08, 'end': 26.16, 'text': '▁mo'}, {'start': 26.16, 'duration': 0.08, 'end': 26.240000000000002, 'text': 't'}, {'start': 26.240000000000002, 'duration': 0.08, 'end': 26.32, 'text': 'or'}, {'start': 26.32, 'duration': 0.08, 'end': 26.4, 'text': 'ing'}, {'start': 26.4, 'duration': 0.08, 'end': 26.48, 'text': '<b>'}, {'start': 26.48, 'duration': 0.08, 'end': 26.56, 'text': '▁app'}, {'start': 26.56, 'duration': 0.16, 'end': 26.72, 'text': 'li'}, {'start': 26.72, 'duration': 0.08, 'end': 26.8, 'text': 'c'}, {'start': 26.8, 'duration': 0.08, 'end': 26.88, 'text': 'ation'}, {'start': 26.88, 'duration': 0.16, 'end': 27.04, 'text': '<b>'}, {'start': 27.04, 'duration': 0.08, 'end': 27.12, 'text': '▁because'}, {'start': 27.12, 'duration': 0.64, 'end': 27.759999999999998, 'text': '<b>'}, {'start': 27.759999999999998, 'duration': 0.08, 'end': 27.84, 'text': '▁what'}, {'start': 27.84, 'duration': 0.08, 'end': 27.92, 'text': '<b>'}, {'start': 27.92, 'duration': 0.08, 'end': 28.0, 'text': '▁it'}, {'start': 28.0, 'duration': 0.16, 'end': 28.16, 'text': '<b>'}, {'start': 28.16, 'duration': 0.08, 'end': 28.240000000000002, 'text': '▁is'}, {'start': 28.240000000000002, 'duration': 0.48, 'end': 28.72, 'text': '<b>'}, {'start': 28.72, 'duration': 0.08, 'end': 28.8, 'text': '▁is'}, {'start': 28.8, 'duration': 0.8, 'end': 29.6, 'text': '<b>'}, {'start': 29.6, 'duration': 0.08, 'end': 29.68, 'text': '▁this'}, {'start': 29.68, 'duration': 0.24, 'end': 29.92, 'text': '<b>'}, {'start': 29.92, 'duration': 0.08, 'end': 30.0, 'text': '.'}, {'start': 30.0, 'duration': 0.08, 'end': 30.08, 'text': '<b>'}, {'start': 30.0, 'duration': 0.08, 'end': 30.08, 'text': '▁This'}, {'start': 30.08, 'duration': 0.24, 'end': 30.32, 'text': '<b>'}, {'start': 30.32, 'duration': 0.08, 'end': 30.4, 'text': '▁ma'}, {'start': 30.4, 'duration': 0.08, 'end': 30.48, 'text': 'ch'}, {'start': 30.48, 'duration': 0.08, 'end': 30.56, 'text': 'ine'}, {'start': 30.56, 'duration': 0.16, 'end': 30.72, 'text': '▁is'}, {'start': 30.72, 'duration': 0.08, 'end': 30.8, 'text': '▁control'}, {'start': 30.8, 'duration': 0.16, 'end': 30.96, 'text': 'le'}, {'start': 30.96, 'duration': 0.08, 'end': 31.04, 'text': 'd'}, {'start': 31.04, 'duration': 0.08, 'end': 31.12, 'text': '▁by'}, {'start': 31.12, 'duration': 0.08, 'end': 31.2, 'text': '▁your'}, {'start': 31.2, 'duration': 0.08, 'end': 31.28, 'text': '▁'}, {'start': 31.28, 'duration': 0.08, 'end': 31.36, 'text': 'i'}, {'start': 31.36, 'duration': 0.08, 'end': 31.44, 'text': 'P'}, {'start': 31.44, 'duration': 0.08, 'end': 31.52, 'text': 'h'}, {'start': 31.52, 'duration': 0.08, 'end': 31.6, 'text': 'one'}, {'start': 31.6, 'duration': 0.08, 'end': 31.68, 'text': ','}, {'start': 31.68, 'duration': 0.08, 'end': 31.76, 'text': '▁right'}, {'start': 31.76, 'duration': 0.08, 'end': 31.84, 'text': '?'}, {'start': 31.84, 'duration': 0.08, 'end': 31.92, 'text': '▁With'}, {'start': 31.92, 'duration': 0.08, 'end': 32.0, 'text': '<b>'}, {'start': 32.0, 'duration': 0.08, 'end': 32.08, 'text': '▁an'}, {'start': 32.08, 'duration': 0.08, 'end': 32.16, 'text': '<b>'}, {'start': 32.16, 'duration': 0.08, 'end': 32.24, 'text': '▁app'}, {'start': 32.24, 'duration': 0.24, 'end': 32.48, 'text': '<b>'}, {'start': 32.48, 'duration': 0.08, 'end': 32.56, 'text': ','}, {'start': 32.56, 'duration': 0.08, 'end': 32.64, 'text': '▁and'}, {'start': 32.64, 'duration': 0.16, 'end': 32.8, 'text': '<b>'}, {'start': 32.8, 'duration': 0.08, 'end': 32.88, 'text': '▁it'}, {'start': 32.88, 'duration': 0.08, 'end': 32.96, 'text': '<b>'}, {'start': 32.96, 'duration': 0.08, 'end': 33.04, 'text': '▁fl'}, {'start': 33.04, 'duration': 0.16, 'end': 33.2, 'text': '<b>'}, {'start': 33.2, 'duration': 0.08, 'end': 33.28, 'text': 'ies'}, {'start': 33.28, 'duration': 0.16, 'end': 33.44, 'text': '<b>'}, {'start': 33.44, 'duration': 0.08, 'end': 33.52, 'text': '▁up'}, {'start': 33.52, 'duration': 0.08, 'end': 33.6, 'text': '<b>'}, {'start': 33.6, 'duration': 0.08, 'end': 33.68, 'text': '▁in'}, {'start': 33.68, 'duration': 0.08, 'end': 33.76, 'text': '▁the'}, {'start': 33.76, 'duration': 0.08, 'end': 33.84, 'text': '▁a'}, {'start': 33.84, 'duration': 0.08, 'end': 33.92, 'text': 'ir'}, {'start': 33.92, 'duration': 0.08, 'end': 34.0, 'text': ','}, {'start': 34.0, 'duration': 0.08, 'end': 34.08, 'text': '▁and'}, {'start': 34.08, 'duration': 0.08, 'end': 34.16, 'text': '▁there'}, {'start': 34.16, 'duration': 0.16, 'end': 34.32, 'text': \"'\"}, {'start': 34.32, 'duration': 0.08, 'end': 34.4, 'text': 's'}, {'start': 34.4, 'duration': 0.08, 'end': 34.480000000000004, 'text': '▁a'}, {'start': 34.480000000000004, 'duration': 0.08, 'end': 34.56, 'text': '▁came'}, {'start': 34.56, 'duration': 0.08, 'end': 34.64, 'text': '<b>'}, {'start': 34.64, 'duration': 0.16, 'end': 34.8, 'text': 'ra'}, {'start': 34.8, 'duration': 0.08, 'end': 34.88, 'text': '▁on'}, {'start': 34.88, 'duration': 0.08, 'end': 34.96, 'text': '▁it'}, {'start': 34.96, 'duration': 0.16, 'end': 35.12, 'text': '<b>'}, {'start': 35.12, 'duration': 0.08, 'end': 35.2, 'text': '.'}], 'segments': [{'start': 0.32, 'duration': 8.48, 'end': 8.8, 'text': \"Ah,<space>now<space>Rich,<space>would<space>you<space>like<space>some<space>pussy?<space>Well,<space>it<space>wasn't<space>on<space>my<space>mind<space>right<space>now.<space>It<space>is<space>now.\"}, {'start': 10.08, 'duration': 7.84, 'end': 17.92, 'text': 'Pussy<space>energy<space>drink.<space>What<space>flavor<space>is<space>it?<space>Flavor.'}, {'start': 20.0, 'duration': 10.0, 'end': 30.0, 'text': \"Dream<space>it.<space>Yeah,<space>moving<space>on.<space>And<space>I'd<space>like<space>to<space>introduce<space>something<space>for<space>which<space>at<space>first<space>I<space>thought<space>I'm<space>going<space>to<space>struggle<space>to<space>find<space>a<space>motoring<space>application<space>because<space>what<space>it<space>is<space>is<space>this.\"}, {'start': 30.0, 'duration': 5.2, 'end': 35.2, 'text': \"This<space>machine<space>is<space>controlled<space>by<space>your<space>iPhone,<space>right?<space>With<space>an<space>app,<space>and<space>it<space>flies<space>up<space>in<space>the<space>air,<space>and<space>there's<space>a<space>camera<space>on<space>it.\"}]}\n"
     ]
    }
   ],
   "source": [
    "print(merged_alignment)\n",
    "alignment_result_new = {\n",
    "\t\"audio_filepath\": audio_filepath,\n",
    "\t\"text\": merged_alignment['text'],\n",
    "\t\"words_level_ctm_filepath\": None,  # Not strictly needed by diarizer\n",
    "\t\"tokens_level_ctm_filepath\": None,\n",
    "\t\"segments_level_ctm_filepath\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 07:28:19 model_utils:492] Skipped conversion for config/subconfig:\n",
      "    {'manifest_filepath': '???', 'out_dir': 'diarizer_output_clust', 'oracle_vad': False, 'collar': 0.25, 'ignore_overlap': True, 'vad': {'model_path': 'vad_multilingual_marblenet', 'external_vad_manifest': None, 'parameters': {'window_length_in_sec': 0.63, 'shift_length_in_sec': 0.01, 'smoothing': False, 'overlap': 0.5, 'onset': 0.8, 'offset': 0.6, 'pad_onset': 0, 'pad_offset': -0.05, 'min_duration_on': 0, 'min_duration_off': 0.6, 'filter_speech_first': True}}, 'speaker_embeddings': {'model_path': 'titanet_large', 'parameters': {'window_length_in_sec': [1.5, 1.25, 1.0, 0.75, 0.5], 'shift_length_in_sec': [0.75, 0.625, 0.5, 0.375, 0.1], 'multiscale_weights': [1, 1, 1, 1, 1], 'save_embeddings': True}}, 'clustering': {'parameters': {'oracle_num_speakers': False, 'max_num_speakers': 8, 'enhanced_count_thres': 80, 'max_rp_threshold': 0.25, 'sparse_search_volume': 30, 'maj_vote_spk_count': False, 'chunk_cluster_count': 50, 'embeddings_per_chunk': 1000}}, 'msdd_model': {'model_path': None, 'parameters': {'use_speaker_model_from_ckpt': True, 'infer_batch_size': 25, 'sigmoid_threshold': [0.7], 'seq_eval_mode': False, 'split_infer': True, 'diar_window_length': 50, 'overlap_infer_spk_limit': 5}}, 'asr': {'model_path': 'stt_en_conformer_ctc_large', 'parameters': {'asr_based_vad': False, 'asr_based_vad_threshold': 1.0, 'asr_batch_size': None, 'decoder_delay_in_sec': None, 'word_ts_anchor_offset': None, 'word_ts_anchor_pos': 'start', 'fix_word_ts_with_VAD': False, 'colored_text': False, 'print_time': True, 'break_lines': False}, 'ctc_decoder_parameters': {'pretrained_language_model': None, 'beam_width': 32, 'alpha': 0.5, 'beta': 2.5}, 'realigning_lm_parameters': {'arpa_language_model': None, 'min_number_of_words': 3, 'max_number_of_words': 10, 'logprob_diff_threshold': 1.2}}}\n",
      "     Reason: Missing mandatory value: diarizer.manifest_filepath\n",
      "        full_key: diarizer.manifest_filepath\n",
      "        object_type=dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:28:19 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
      "[NeMo I 2025-02-09 07:28:19 cloud:58] Found existing object /your/desired/path/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
      "[NeMo I 2025-02-09 07:28:19 cloud:64] Re-using file from: /your/desired/path/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
      "[NeMo I 2025-02-09 07:28:19 common:826] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 07:28:19 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      shift:\n",
      "        prob: 0.5\n",
      "        min_shift_ms: -10.0\n",
      "        max_shift_ms: 10.0\n",
      "      white_noise:\n",
      "        prob: 0.5\n",
      "        min_level: -90\n",
      "        max_level: -46\n",
      "        norm: true\n",
      "      noise:\n",
      "        prob: 0.5\n",
      "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 30\n",
      "        max_gain_db: 300.0\n",
      "        norm: true\n",
      "      gain:\n",
      "        prob: 0.5\n",
      "        min_gain_dbfs: -10.0\n",
      "        max_gain_dbfs: 10.0\n",
      "        norm: true\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2025-02-09 07:28:19 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: false\n",
      "    val_loss_idx: 0\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2025-02-09 07:28:19 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    test_loss_idx: 0\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:28:19 features:305] PADDING: 16\n",
      "[NeMo I 2025-02-09 07:28:19 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /your/desired/path/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
      "[NeMo I 2025-02-09 07:28:19 clustering_diarizer:160] Loading pretrained titanet_large model from NGC\n",
      "[NeMo I 2025-02-09 07:28:19 cloud:58] Found existing object /your/desired/path/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n",
      "[NeMo I 2025-02-09 07:28:19 cloud:64] Re-using file from: /your/desired/path/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n",
      "[NeMo I 2025-02-09 07:28:19 common:826] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 07:28:19 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2025-02-09 07:28:19 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:28:19 features:305] PADDING: 16\n",
      "[NeMo I 2025-02-09 07:28:20 save_restore_connector:272] Model EncDecSpeakerLabelModel was successfully restored from /your/desired/path/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 07:28:20 clustering_diarizer:408] Deleting previous clustering diarizer outputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running diarization inference...\n",
      "[NeMo I 2025-02-09 07:28:20 speaker_utils:93] Number of files to diarize: 1\n",
      "[NeMo I 2025-02-09 07:28:20 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  4.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:28:20 vad_utils:107] The prepared manifest file exists. Overwriting!\n",
      "[NeMo I 2025-02-09 07:28:20 classification_models:293] Perform streaming frame-level VAD\n",
      "[NeMo I 2025-02-09 07:28:20 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2025-02-09 07:28:20 collections:741] Dataset successfully loaded with 1 items and total duration provided from manifest is  0.01 hours.\n",
      "[NeMo I 2025-02-09 07:28:20 collections:746] # 1 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "vad: 100%|██████████| 1/1 [00:01<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:28:21 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 14.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:28:21 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, diarizer_output_clust/speaker_outputs/subsegments_scale0.json\n",
      "[NeMo I 2025-02-09 07:28:21 clustering_diarizer:347] Extracting embeddings for Diarization\n",
      "[NeMo I 2025-02-09 07:28:21 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2025-02-09 07:28:21 collections:741] Dataset successfully loaded with 32 items and total duration provided from manifest is  0.01 hours.\n",
      "[NeMo I 2025-02-09 07:28:21 collections:746] # 32 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:28:22 clustering_diarizer:393] Saved embedding files to diarizer_output_clust/speaker_outputs/embeddings\n",
      "[NeMo I 2025-02-09 07:28:22 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, diarizer_output_clust/speaker_outputs/subsegments_scale1.json\n",
      "[NeMo I 2025-02-09 07:28:22 clustering_diarizer:347] Extracting embeddings for Diarization\n",
      "[NeMo I 2025-02-09 07:28:22 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2025-02-09 07:28:22 collections:741] Dataset successfully loaded with 38 items and total duration provided from manifest is  0.01 hours.\n",
      "[NeMo I 2025-02-09 07:28:22 collections:746] # 38 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:28:22 clustering_diarizer:393] Saved embedding files to diarizer_output_clust/speaker_outputs/embeddings\n",
      "[NeMo I 2025-02-09 07:28:22 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, diarizer_output_clust/speaker_outputs/subsegments_scale2.json\n",
      "[NeMo I 2025-02-09 07:28:22 clustering_diarizer:347] Extracting embeddings for Diarization\n",
      "[NeMo I 2025-02-09 07:28:22 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2025-02-09 07:28:22 collections:741] Dataset successfully loaded with 48 items and total duration provided from manifest is  0.01 hours.\n",
      "[NeMo I 2025-02-09 07:28:22 collections:746] # 48 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:28:23 clustering_diarizer:393] Saved embedding files to diarizer_output_clust/speaker_outputs/embeddings\n",
      "[NeMo I 2025-02-09 07:28:23 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, diarizer_output_clust/speaker_outputs/subsegments_scale3.json\n",
      "[NeMo I 2025-02-09 07:28:23 clustering_diarizer:347] Extracting embeddings for Diarization\n",
      "[NeMo I 2025-02-09 07:28:23 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2025-02-09 07:28:23 collections:741] Dataset successfully loaded with 65 items and total duration provided from manifest is  0.01 hours.\n",
      "[NeMo I 2025-02-09 07:28:23 collections:746] # 65 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:28:24 clustering_diarizer:393] Saved embedding files to diarizer_output_clust/speaker_outputs/embeddings\n",
      "[NeMo I 2025-02-09 07:28:24 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, diarizer_output_clust/speaker_outputs/subsegments_scale4.json\n",
      "[NeMo I 2025-02-09 07:28:24 clustering_diarizer:347] Extracting embeddings for Diarization\n",
      "[NeMo I 2025-02-09 07:28:24 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2025-02-09 07:28:24 collections:741] Dataset successfully loaded with 236 items and total duration provided from manifest is  0.03 hours.\n",
      "[NeMo I 2025-02-09 07:28:24 collections:746] # 236 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/5] extract embeddings: 100%|██████████| 4/4 [00:01<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:28:25 clustering_diarizer:393] Saved embedding files to diarizer_output_clust/speaker_outputs/embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "clustering: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 07:28:25 clustering_diarizer:461] Outputs are saved in /usr/src/app/tests/diarizer_output_clust directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2025-02-09 07:28:25 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diarization complete. Predicted RTTM at: diarizer_output_clust/pred_rttms/mono_output.rttm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'diarizer_output_clust/pred_rttms/mono_output.rttm'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diarizer_instance_clust = Diarizer(num_speakers=None, use_oracle_vad=False, out_dir=\"diarizer_output_clust\")\n",
    "diarizer_instance_clust.diarize(alignment_result_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
