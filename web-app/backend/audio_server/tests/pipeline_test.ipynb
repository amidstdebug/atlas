{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "logging.basicConfig(level = logging.INFO)\n",
    "logging.getLogger(\"nemo_logger\").setLevel(logging.ERROR)\n",
    "\n",
    "os.environ[\"NEMO_CACHE_DIR\"] = \"/usr/src/app/models\"\n",
    "sys.path.insert(0, '/usr/src/app/inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0209 10:22:04.722829 140262736229504 zarr.py:57] `zarr` distributed checkpoint backend is deprecated. Please switch to PyTorch Distributed format (`torch_dist`).\n"
     ]
    }
   ],
   "source": [
    "from canary_transcriber import CanaryTranscriber\n",
    "from force_aligner import ForceAligner\n",
    "from diarizer import Diarizer\n",
    "from pipeline import InferencePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:09 mixins:197] _setup_tokenizer: detected an aggregate tokenizer\n",
      "[NeMo I 2025-02-09 10:22:09 mixins:336] Tokenizer SentencePieceTokenizer initialized with 32 tokens\n",
      "[NeMo I 2025-02-09 10:22:09 mixins:336] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-02-09 10:22:09 mixins:336] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-02-09 10:22:09 mixins:336] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-02-09 10:22:09 mixins:336] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n",
      "[NeMo I 2025-02-09 10:22:09 aggregate_tokenizer:73] Aggregate vocab size: 4128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 10:22:09 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    tarred_audio_filepaths: null\n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    shuffle: true\n",
      "    batch_size: null\n",
      "    num_workers: 8\n",
      "    use_lhotse: true\n",
      "    max_duration: 40\n",
      "    pin_memory: true\n",
      "    use_bucketing: false\n",
      "    bucket_duration_bins: null\n",
      "    num_buckets: 1\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    batch_duration: 360\n",
      "    quadratic_duration: 15\n",
      "    bucket_buffer_size: 20000\n",
      "    shuffle_buffer_size: 10000\n",
      "    \n",
      "[NeMo W 2025-02-09 10:22:09 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 8\n",
      "    shuffle: false\n",
      "    num_workers: 0\n",
      "    pin_memory: true\n",
      "    tarred_audio_filepaths: null\n",
      "    use_lhotse: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: false\n",
      "    \n",
      "[NeMo W 2025-02-09 10:22:09 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 0\n",
      "    pin_memory: true\n",
      "    tarred_audio_filepaths: null\n",
      "    use_lhotse: true\n",
      "    text_field: answer\n",
      "    lang_field: target_lang\n",
      "    use_bucketing: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:09 features:305] PADDING: 0\n",
      "[NeMo I 2025-02-09 10:22:17 save_restore_connector:272] Model EncDecMultiTaskModel was successfully restored from /root/.cache/huggingface/hub/models--nvidia--canary-1b/snapshots/dd32c0c709e2bfc79f583e16b9df4b3a160f7e86/canary-1b.nemo.\n",
      "[NeMo I 2025-02-09 10:22:17 aed_multitask_models:260] Changed decoding strategy to \n",
      "    strategy: beam\n",
      "    compute_hypothesis_token_set: false\n",
      "    preserve_alignments: null\n",
      "    compute_langs: false\n",
      "    beam:\n",
      "      beam_size: 1\n",
      "      search_type: default\n",
      "      len_pen: 1.0\n",
      "      max_generation_delta: 20\n",
      "      return_best_hypothesis: true\n",
      "      preserve_alignments: false\n",
      "    temperature: 1.0\n",
      "    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 10:22:17 model_utils:492] Skipped conversion for config/subconfig:\n",
      "    {'manifest_filepath': '???', 'out_dir': 'diarizer_output', 'oracle_vad': False, 'collar': 0.25, 'ignore_overlap': True, 'vad': {'model_path': 'vad_multilingual_marblenet', 'external_vad_manifest': None, 'parameters': {'window_length_in_sec': 0.63, 'shift_length_in_sec': 0.01, 'smoothing': False, 'overlap': 0.5, 'onset': 0.8, 'offset': 0.6, 'pad_onset': 0, 'pad_offset': -0.05, 'min_duration_on': 0, 'min_duration_off': 0.6, 'filter_speech_first': True}}, 'speaker_embeddings': {'model_path': 'titanet_large', 'parameters': {'window_length_in_sec': [1.5, 1.25, 1.0, 0.75, 0.5], 'shift_length_in_sec': [0.75, 0.625, 0.5, 0.375, 0.1], 'multiscale_weights': [1, 1, 1, 1, 1], 'save_embeddings': True}}, 'clustering': {'parameters': {'oracle_num_speakers': False, 'max_num_speakers': 8, 'enhanced_count_thres': 80, 'max_rp_threshold': 0.25, 'sparse_search_volume': 30, 'maj_vote_spk_count': False, 'chunk_cluster_count': 50, 'embeddings_per_chunk': 10000}}, 'msdd_model': {'model_path': None, 'parameters': {'use_speaker_model_from_ckpt': True, 'infer_batch_size': 25, 'sigmoid_threshold': [0.7], 'seq_eval_mode': False, 'split_infer': True, 'diar_window_length': 50, 'overlap_infer_spk_limit': 5}}, 'asr': {'model_path': 'stt_en_conformer_ctc_large', 'parameters': {'asr_based_vad': False, 'asr_based_vad_threshold': 1.0, 'asr_batch_size': None, 'decoder_delay_in_sec': None, 'word_ts_anchor_offset': None, 'word_ts_anchor_pos': 'start', 'fix_word_ts_with_VAD': False, 'colored_text': False, 'print_time': True, 'break_lines': False}, 'ctc_decoder_parameters': {'pretrained_language_model': None, 'beam_width': 32, 'alpha': 0.5, 'beta': 2.5}, 'realigning_lm_parameters': {'arpa_language_model': None, 'min_number_of_words': 3, 'max_number_of_words': 10, 'logprob_diff_threshold': 1.2}}}\n",
      "     Reason: Missing mandatory value: diarizer.manifest_filepath\n",
      "        full_key: diarizer.manifest_filepath\n",
      "        object_type=dict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:17 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
      "[NeMo I 2025-02-09 10:22:17 cloud:58] Found existing object /usr/src/app/models/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
      "[NeMo I 2025-02-09 10:22:17 cloud:64] Re-using file from: /usr/src/app/models/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
      "[NeMo I 2025-02-09 10:22:18 common:826] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 10:22:18 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      shift:\n",
      "        prob: 0.5\n",
      "        min_shift_ms: -10.0\n",
      "        max_shift_ms: 10.0\n",
      "      white_noise:\n",
      "        prob: 0.5\n",
      "        min_level: -90\n",
      "        max_level: -46\n",
      "        norm: true\n",
      "      noise:\n",
      "        prob: 0.5\n",
      "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 30\n",
      "        max_gain_db: 300.0\n",
      "        norm: true\n",
      "      gain:\n",
      "        prob: 0.5\n",
      "        min_gain_dbfs: -10.0\n",
      "        max_gain_dbfs: 10.0\n",
      "        norm: true\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2025-02-09 10:22:18 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: false\n",
      "    val_loss_idx: 0\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2025-02-09 10:22:18 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    test_loss_idx: 0\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:18 features:305] PADDING: 16\n",
      "[NeMo I 2025-02-09 10:22:18 save_restore_connector:272] Model EncDecClassificationModel was successfully restored from /usr/src/app/models/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
      "[NeMo I 2025-02-09 10:22:18 clustering_diarizer:160] Loading pretrained titanet_large model from NGC\n",
      "[NeMo I 2025-02-09 10:22:18 cloud:58] Found existing object /usr/src/app/models/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n",
      "[NeMo I 2025-02-09 10:22:18 cloud:64] Re-using file from: /usr/src/app/models/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n",
      "[NeMo I 2025-02-09 10:22:18 common:826] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 10:22:19 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2025-02-09 10:22:19 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:19 features:305] PADDING: 16\n",
      "[NeMo I 2025-02-09 10:22:20 save_restore_connector:272] Model EncDecSpeakerLabelModel was successfully restored from /usr/src/app/models/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n"
     ]
    }
   ],
   "source": [
    "CHUNK_DURATION = 30 # Transcribe and Force Align every 30 second audio chunk\n",
    "\n",
    "transcriber = CanaryTranscriber(model_name='nvidia/canary-1b')\n",
    "force_aligner = ForceAligner(model_name=None)\n",
    "diarizer_instance = Diarizer(\n",
    "    config_path=None,\n",
    "    out_dir=\"diarizer_output\",\n",
    "    num_speakers=None,\n",
    "    use_oracle_vad=False\n",
    ")\n",
    "\n",
    "pipeline = InferencePipeline(\n",
    "    transcriber=transcriber,\n",
    "    force_aligner=force_aligner,\n",
    "    diarizer=diarizer_instance,\n",
    "\tchunk_duration_sec=CHUNK_DURATION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 1it [00:04,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:24 align:159] Hydra config: pretrained_name: stt_en_fastconformer_hybrid_large_pc\n",
      "    model_path: null\n",
      "    manifest_filepath: /tmp/nfa_6viq0etz/e563a7c3-b41d-474c-897f-c671308fdca1_manifest.json\n",
      "    output_dir: /tmp/nfa_6viq0etz/nfa_output\n",
      "    align_using_pred_text: false\n",
      "    transcribe_device: null\n",
      "    viterbi_device: null\n",
      "    batch_size: 1\n",
      "    use_local_attention: true\n",
      "    additional_segment_grouping_separator: '|'\n",
      "    audio_filepath_parts_in_utt_id: 1\n",
      "    use_buffered_chunked_streaming: false\n",
      "    chunk_len_in_secs: 1.6\n",
      "    total_buffer_in_secs: 4.0\n",
      "    chunk_batch_size: 32\n",
      "    simulate_cache_aware_streaming: false\n",
      "    save_output_file_formats:\n",
      "    - ctm\n",
      "    ctm_file_config:\n",
      "      remove_blank_tokens: false\n",
      "      minimum_timestamp_duration: 0.0\n",
      "    ass_file_config:\n",
      "      fontsize: 20\n",
      "      vertical_alignment: center\n",
      "      resegment_text_to_fill_space: false\n",
      "      max_lines_per_segment: 2\n",
      "      text_already_spoken_rgb:\n",
      "      - 49\n",
      "      - 46\n",
      "      - 61\n",
      "      text_being_spoken_rgb:\n",
      "      - 57\n",
      "      - 171\n",
      "      - 9\n",
      "      text_not_yet_spoken_rgb:\n",
      "      - 194\n",
      "      - 193\n",
      "      - 199\n",
      "    \n",
      "[NeMo I 2025-02-09 10:22:24 align:228] Device to be used for transcription step (`transcribe_device`) is cuda\n",
      "[NeMo I 2025-02-09 10:22:24 align:234] Device to be used for viterbi step (`viterbi_device`) is cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2025-02-09 10:22:24 align:237] One or both of transcribe_device and viterbi_device are GPUs. If you run into OOM errors it may help to change both devices to be the CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:24 cloud:58] Found existing object /usr/src/app/models/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2025-02-09 10:22:24 cloud:64] Re-using file from: /usr/src/app/models/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo\n",
      "[NeMo I 2025-02-09 10:22:24 common:826] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2025-02-09 10:22:31 mixins:173] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 10:22:32 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: false\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 1.0\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20\n",
      "    min_duration: 0.1\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-02-09 10:22:32 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: fisher_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: europarl_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: librispeech_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mcv11_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: nsc1_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: spgi_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: voxpopuli_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mls_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    max_duration: 20\n",
      "    \n",
      "[NeMo W 2025-02-09 10:22:32 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:32 features:305] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 10:22:32 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:33 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 10:22:33 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 10:22:33 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 10:22:33 save_restore_connector:272] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /usr/src/app/models/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2025-02-09 10:22:33 hybrid_rnnt_ctc_bpe_models:464] No `decoding_cfg` passed when changing decoding strategy, using internal config\n",
      "[NeMo I 2025-02-09 10:22:33 hybrid_rnnt_ctc_bpe_models:488] Changed decoding strategy of the CTC decoder to \n",
      "    strategy: greedy\n",
      "    preserve_alignments: null\n",
      "    compute_timestamps: null\n",
      "    word_seperator: ' '\n",
      "    ctc_timestamp_type: all\n",
      "    batch_dim_index: 0\n",
      "    greedy:\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "      return_best_hypothesis: true\n",
      "      beam_alpha: 1.0\n",
      "      beam_beta: 0.0\n",
      "      kenlm_path: null\n",
      "      flashlight_cfg:\n",
      "        lexicon_path: null\n",
      "        boost_path: null\n",
      "        beam_size_token: 16\n",
      "        beam_threshold: 20.0\n",
      "        unk_weight: -.inf\n",
      "        sil_weight: 0.0\n",
      "      pyctcdecode_cfg:\n",
      "        beam_prune_logp: -10.0\n",
      "        token_min_logp: -5.0\n",
      "        prune_history: false\n",
      "        hotwords: null\n",
      "        hotword_weight: 10.0\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      tdt_include_duration: false\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2025-02-09 10:22:33 align:250] Flag use_local_attention is set to True => will try to use local attention for model if it allows it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing:   0%|          | 0/1 [00:00<?, ?it/s][NeMo W 2025-02-09 10:22:35 ctc_greedy_decoding:168] CTC decoding strategy 'greedy' is slower than 'greedy_batch', which implements the same exact interface. Consider changing your strategy to 'greedy_batch' for a free performance improvement.\n",
      "Transcribing: 100%|██████████| 1/1 [00:01<00:00,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:35 data_prep:822] Calculated that the model downsample factor is 8 and therefore the ASR model output timestep duration is 0.08 -- will use this for all batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcribing: 1it [00:01,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:36 align:159] Hydra config: pretrained_name: stt_en_fastconformer_hybrid_large_pc\n",
      "    model_path: null\n",
      "    manifest_filepath: /tmp/nfa_qs974_rr/860c9b99-00a5-4c16-82d4-746d8680a7d9_manifest.json\n",
      "    output_dir: /tmp/nfa_qs974_rr/nfa_output\n",
      "    align_using_pred_text: false\n",
      "    transcribe_device: null\n",
      "    viterbi_device: null\n",
      "    batch_size: 1\n",
      "    use_local_attention: true\n",
      "    additional_segment_grouping_separator: '|'\n",
      "    audio_filepath_parts_in_utt_id: 1\n",
      "    use_buffered_chunked_streaming: false\n",
      "    chunk_len_in_secs: 1.6\n",
      "    total_buffer_in_secs: 4.0\n",
      "    chunk_batch_size: 32\n",
      "    simulate_cache_aware_streaming: false\n",
      "    save_output_file_formats:\n",
      "    - ctm\n",
      "    ctm_file_config:\n",
      "      remove_blank_tokens: false\n",
      "      minimum_timestamp_duration: 0.0\n",
      "    ass_file_config:\n",
      "      fontsize: 20\n",
      "      vertical_alignment: center\n",
      "      resegment_text_to_fill_space: false\n",
      "      max_lines_per_segment: 2\n",
      "      text_already_spoken_rgb:\n",
      "      - 49\n",
      "      - 46\n",
      "      - 61\n",
      "      text_being_spoken_rgb:\n",
      "      - 57\n",
      "      - 171\n",
      "      - 9\n",
      "      text_not_yet_spoken_rgb:\n",
      "      - 194\n",
      "      - 193\n",
      "      - 199\n",
      "    \n",
      "[NeMo I 2025-02-09 10:22:36 align:228] Device to be used for transcription step (`transcribe_device`) is cuda\n",
      "[NeMo I 2025-02-09 10:22:36 align:234] Device to be used for viterbi step (`viterbi_device`) is cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2025-02-09 10:22:36 align:237] One or both of transcribe_device and viterbi_device are GPUs. If you run into OOM errors it may help to change both devices to be the CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:36 cloud:58] Found existing object /usr/src/app/models/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2025-02-09 10:22:36 cloud:64] Re-using file from: /usr/src/app/models/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo\n",
      "[NeMo I 2025-02-09 10:22:36 common:826] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2025-02-09 10:22:43 mixins:173] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 10:22:44 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    is_concat: false\n",
      "    concat_sampling_technique: random\n",
      "    concat_sampling_temperature: 8\n",
      "    concat_shuffle: true\n",
      "    concat_sampling_scale: 1.0\n",
      "    manifest_filepath:\n",
      "    - - /data/mml/en/tarred_train/pcstrip_sharded_manifests/manifest__OP_0..511_CL_.json\n",
      "    tarred_audio_filepaths:\n",
      "    - - /data/mml/en/tarred_train/audio__OP_0..511_CL_.tar\n",
      "    concat_sampling_probabilities:\n",
      "    - 1.0\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20\n",
      "    min_duration: 0.1\n",
      "    is_tarred: true\n",
      "    shard_manifests: true\n",
      "    defer_setup: true\n",
      "    shuffle_n: 528387\n",
      "    bucketing_strategy: synced_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-02-09 10:22:44 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    ds_item:\n",
      "    - name: en_\n",
      "      is_concat: true\n",
      "      concat_sampling_technique: random\n",
      "      concat_sampling_seed: 1234\n",
      "      concat_shuffle: false\n",
      "      concat_sampling_scale: 0.25\n",
      "      concat_sampling_probabilities:\n",
      "      - 0.088929287\n",
      "      - 0.116404906\n",
      "      - 0.101879436\n",
      "      - 0.171855007\n",
      "      - 0.160962192\n",
      "      - 0.092674082\n",
      "      - 0.041152255\n",
      "      - 0.226142835\n",
      "      manifest_filepath:\n",
      "      - - /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "        - /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: fisher_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/fisher/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: europarl_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/europarl/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: librispeech_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/librispeech/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mcv11_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mcv11/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: nsc1_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/nsc1/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: spgi_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/SPGI/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: voxpopuli_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/voxpopuli/audio_manifest_dev_clean_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    - name: mls_\n",
      "      is_concat: false\n",
      "      manifest_filepath: /data/mml/en/val_test/mls_dev/mls_dev_pcstrip_en.json\n",
      "      sample_rate: 16000\n",
      "      batch_size: 64\n",
      "      shuffle: false\n",
      "      num_workers: 1\n",
      "      pin_memory: true\n",
      "      max_duration: 20.0\n",
      "      min_duration: 0.1\n",
      "      use_start_end_token: false\n",
      "    max_duration: 20\n",
      "    \n",
      "[NeMo W 2025-02-09 10:22:44 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:44 features:305] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-09 10:22:44 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:45 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 10:22:45 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 10:22:45 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-02-09 10:22:45 save_restore_connector:272] Model EncDecHybridRNNTCTCBPEModel was successfully restored from /usr/src/app/models/stt_en_fastconformer_hybrid_large_pc/465b32000fc320f5905fda11a1866ef6/stt_en_fastconformer_hybrid_large_pc.nemo.\n",
      "[NeMo I 2025-02-09 10:22:45 hybrid_rnnt_ctc_bpe_models:464] No `decoding_cfg` passed when changing decoding strategy, using internal config\n",
      "[NeMo I 2025-02-09 10:22:45 hybrid_rnnt_ctc_bpe_models:488] Changed decoding strategy of the CTC decoder to \n",
      "    strategy: greedy\n",
      "    preserve_alignments: null\n",
      "    compute_timestamps: null\n",
      "    word_seperator: ' '\n",
      "    ctc_timestamp_type: all\n",
      "    batch_dim_index: 0\n",
      "    greedy:\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "      preserve_frame_confidence: false\n",
      "      confidence_method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    beam:\n",
      "      beam_size: 4\n",
      "      search_type: default\n",
      "      preserve_alignments: false\n",
      "      compute_timestamps: false\n",
      "      return_best_hypothesis: true\n",
      "      beam_alpha: 1.0\n",
      "      beam_beta: 0.0\n",
      "      kenlm_path: null\n",
      "      flashlight_cfg:\n",
      "        lexicon_path: null\n",
      "        boost_path: null\n",
      "        beam_size_token: 16\n",
      "        beam_threshold: 20.0\n",
      "        unk_weight: -.inf\n",
      "        sil_weight: 0.0\n",
      "      pyctcdecode_cfg:\n",
      "        beam_prune_logp: -10.0\n",
      "        token_min_logp: -5.0\n",
      "        prune_history: false\n",
      "        hotwords: null\n",
      "        hotword_weight: 10.0\n",
      "    confidence_cfg:\n",
      "      preserve_frame_confidence: false\n",
      "      preserve_token_confidence: false\n",
      "      preserve_word_confidence: false\n",
      "      exclude_blank: true\n",
      "      aggregation: min\n",
      "      tdt_include_duration: false\n",
      "      method_cfg:\n",
      "        name: entropy\n",
      "        entropy_type: tsallis\n",
      "        alpha: 0.33\n",
      "        entropy_norm: exp\n",
      "        temperature: DEPRECATED\n",
      "    temperature: 1.0\n",
      "    \n",
      "[NeMo I 2025-02-09 10:22:45 align:250] Flag use_local_attention is set to True => will try to use local attention for model if it allows it\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|██████████| 1/1 [00:00<00:00, 11.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:45 data_prep:822] Calculated that the model downsample factor is 8 and therefore the ASR model output timestep duration is 0.08 -- will use this for all batches\n",
      "Running diarization inference...\n",
      "[NeMo I 2025-02-09 10:22:45 speaker_utils:93] Number of files to diarize: 1\n",
      "[NeMo I 2025-02-09 10:22:45 clustering_diarizer:313] Split long audio file to avoid CUDA memory issue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "splitting manifest: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:46 classification_models:293] Perform streaming frame-level VAD\n",
      "[NeMo I 2025-02-09 10:22:46 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2025-02-09 10:22:46 collections:741] Dataset successfully loaded with 1 items and total duration provided from manifest is  0.01 hours.\n",
      "[NeMo I 2025-02-09 10:22:46 collections:746] # 1 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "vad: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:47 clustering_diarizer:266] Converting frame level prediction to speech/no-speech segment in start and end times format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "creating speech segments: 100%|██████████| 1/1 [00:00<00:00, 13.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:47 clustering_diarizer:291] Subsegmentation for embedding extraction: scale0, diarizer_output/speaker_outputs/subsegments_scale0.json\n",
      "[NeMo I 2025-02-09 10:22:47 clustering_diarizer:347] Extracting embeddings for Diarization\n",
      "[NeMo I 2025-02-09 10:22:47 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2025-02-09 10:22:47 collections:741] Dataset successfully loaded with 32 items and total duration provided from manifest is  0.01 hours.\n",
      "[NeMo I 2025-02-09 10:22:47 collections:746] # 32 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:47 clustering_diarizer:393] Saved embedding files to diarizer_output/speaker_outputs/embeddings\n",
      "[NeMo I 2025-02-09 10:22:47 clustering_diarizer:291] Subsegmentation for embedding extraction: scale1, diarizer_output/speaker_outputs/subsegments_scale1.json\n",
      "[NeMo I 2025-02-09 10:22:47 clustering_diarizer:347] Extracting embeddings for Diarization\n",
      "[NeMo I 2025-02-09 10:22:47 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2025-02-09 10:22:47 collections:741] Dataset successfully loaded with 38 items and total duration provided from manifest is  0.01 hours.\n",
      "[NeMo I 2025-02-09 10:22:47 collections:746] # 38 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[2/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:47 clustering_diarizer:393] Saved embedding files to diarizer_output/speaker_outputs/embeddings\n",
      "[NeMo I 2025-02-09 10:22:47 clustering_diarizer:291] Subsegmentation for embedding extraction: scale2, diarizer_output/speaker_outputs/subsegments_scale2.json\n",
      "[NeMo I 2025-02-09 10:22:47 clustering_diarizer:347] Extracting embeddings for Diarization\n",
      "[NeMo I 2025-02-09 10:22:47 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2025-02-09 10:22:47 collections:741] Dataset successfully loaded with 48 items and total duration provided from manifest is  0.01 hours.\n",
      "[NeMo I 2025-02-09 10:22:47 collections:746] # 48 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[3/5] extract embeddings: 100%|██████████| 1/1 [00:00<00:00,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:48 clustering_diarizer:393] Saved embedding files to diarizer_output/speaker_outputs/embeddings\n",
      "[NeMo I 2025-02-09 10:22:48 clustering_diarizer:291] Subsegmentation for embedding extraction: scale3, diarizer_output/speaker_outputs/subsegments_scale3.json\n",
      "[NeMo I 2025-02-09 10:22:48 clustering_diarizer:347] Extracting embeddings for Diarization\n",
      "[NeMo I 2025-02-09 10:22:48 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2025-02-09 10:22:48 collections:741] Dataset successfully loaded with 65 items and total duration provided from manifest is  0.01 hours.\n",
      "[NeMo I 2025-02-09 10:22:48 collections:746] # 65 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[4/5] extract embeddings: 100%|██████████| 2/2 [00:00<00:00,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:48 clustering_diarizer:393] Saved embedding files to diarizer_output/speaker_outputs/embeddings\n",
      "[NeMo I 2025-02-09 10:22:48 clustering_diarizer:291] Subsegmentation for embedding extraction: scale4, diarizer_output/speaker_outputs/subsegments_scale4.json\n",
      "[NeMo I 2025-02-09 10:22:48 clustering_diarizer:347] Extracting embeddings for Diarization\n",
      "[NeMo I 2025-02-09 10:22:48 collections:740] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2025-02-09 10:22:48 collections:741] Dataset successfully loaded with 236 items and total duration provided from manifest is  0.03 hours.\n",
      "[NeMo I 2025-02-09 10:22:48 collections:746] # 236 files loaded accounting to # 1 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[5/5] extract embeddings: 100%|██████████| 4/4 [00:00<00:00,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:49 clustering_diarizer:393] Saved embedding files to diarizer_output/speaker_outputs/embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "clustering: 100%|██████████| 1/1 [00:00<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-09 10:22:50 clustering_diarizer:461] Outputs are saved in /usr/src/app/tests/diarizer_output directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[NeMo W 2025-02-09 10:22:50 der:185] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diarization complete. Predicted RTTM at: diarizer_output/pred_rttms/mono_output.rttm\n"
     ]
    }
   ],
   "source": [
    "audio_filepath = \"/usr/src/app/mono_output.wav\"\n",
    "inference_result = pipeline.run_inference(audio_filepath, text=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def assign_speakers_by_sentence(alignment_items, transcript_text):\n",
    "    # Split transcript text into sentences using a tokenizer\n",
    "    sentences = nltk.sent_tokenize(transcript_text)\n",
    "    \n",
    "    # For each sentence, find the alignment items that belong to that sentence.\n",
    "    # This example assumes a simple greedy assignment based on text matching or timing.\n",
    "    # In practice, you might align based on timestamps.\n",
    "    updated_items = []\n",
    "    current_index = 0\n",
    "    for sentence in sentences:\n",
    "        # Split sentence into words (simple tokenization)\n",
    "        sentence_words = sentence.split()\n",
    "        sentence_length = len(sentence_words)\n",
    "        \n",
    "        # Assume that the next `sentence_length` words in alignment_items belong to this sentence.\n",
    "        # (In real cases, you may need a more robust method to map words to sentences based on timing.)\n",
    "        sentence_items = alignment_items[current_index: current_index + sentence_length]\n",
    "        current_index += sentence_length\n",
    "        \n",
    "        # Compute majority speaker label for this sentence\n",
    "        speaker_counts = {}\n",
    "        for item in sentence_items:\n",
    "            speaker = item.get(\"speaker\", \"unknown\")\n",
    "            speaker_counts[speaker] = speaker_counts.get(speaker, 0) + 1\n",
    "        \n",
    "        if speaker_counts:\n",
    "            majority_speaker = max(speaker_counts, key=speaker_counts.get)\n",
    "        else:\n",
    "            majority_speaker = \"unknown\"\n",
    "        \n",
    "        # Update all items in this sentence with the majority speaker\n",
    "        for item in sentence_items:\n",
    "            item[\"speaker\"] = majority_speaker\n",
    "        \n",
    "        updated_items.extend(sentence_items)\n",
    "    return updated_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prettify_transcript(alignment_items):\n",
    "    \"\"\"\n",
    "    Convert a list of dictionaries like:\n",
    "        [\n",
    "          {\"start\": 0.08, \"end\": 0.16, \"text\": \"He\", \"speaker\": \"speaker_1\"},\n",
    "          {\"start\": 0.24, \"end\": 0.80, \"text\": \"frequently\", \"speaker\": \"speaker_1\"},\n",
    "          ...\n",
    "        ]\n",
    "    into a more human-readable transcript.\n",
    "\n",
    "    Returns a string that groups consecutive words from the same speaker,\n",
    "    and prints them with a time range and speaker label, e.g.:\n",
    "\n",
    "        speaker_1 (0.08 - 2.48): He frequently asks, Are you okay during sex?\n",
    "        speaker_3 (2.48 - 3.84): Show us, show us. What does that look?\n",
    "    \"\"\"\n",
    "    if not alignment_items:\n",
    "        return \"\"\n",
    "\n",
    "    # Sort items by start time (in case they're not already)\n",
    "    alignment_items = sorted(alignment_items, key=lambda x: x[\"start\"])\n",
    "\n",
    "    # We'll accumulate lines of text for each speaker\n",
    "    lines = []\n",
    "\n",
    "    # Start the \"current\" segment with the first word\n",
    "    current_speaker = alignment_items[0][\"speaker\"]\n",
    "    current_start = alignment_items[0][\"start\"]\n",
    "    current_texts = [alignment_items[0][\"text\"]]\n",
    "    current_end = alignment_items[0][\"end\"]\n",
    "\n",
    "    for item in alignment_items[1:]:\n",
    "        spk = item.get(\"speaker\", \"unknown\")\n",
    "        st = item.get(\"start\", 0.0)\n",
    "        ed = item.get(\"end\", 0.0)\n",
    "        txt = item.get(\"text\", \"\")\n",
    "\n",
    "        if spk == current_speaker:\n",
    "            # Continue the same speaker segment\n",
    "            # Update end time and append text\n",
    "            current_end = ed\n",
    "            current_texts.append(txt)\n",
    "        else:\n",
    "            # We've reached a new speaker, so finalize the current speaker segment\n",
    "            line = _format_line(current_speaker, current_start, current_end, current_texts)\n",
    "            lines.append(line)\n",
    "\n",
    "            # Start a new speaker segment\n",
    "            current_speaker = spk\n",
    "            current_start = st\n",
    "            current_end = ed\n",
    "            current_texts = [txt]\n",
    "\n",
    "    # Don't forget the last segment\n",
    "    final_line = _format_line(current_speaker, current_start, current_end, current_texts)\n",
    "    lines.append(final_line)\n",
    "\n",
    "    # Join all lines into a single string\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def _format_line(speaker, start, end, text_list):\n",
    "    \"\"\"\n",
    "    Helper function to join the text tokens and format a single line of transcript.\n",
    "    \"\"\"\n",
    "    # Round times for readability\n",
    "    start_rounded = round(start, 2)\n",
    "    end_rounded = round(end, 2)\n",
    "    text_str = \" \".join(text_list)\n",
    "\n",
    "    # Example output: speaker_1 (0.08 - 2.48): He frequently asks, Are you okay...\n",
    "    return f\"{speaker} ({start_rounded} - {end_rounded}): {text_str}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker_1 (0.4 - 5.28): Ah, now, Rich, would you like some pussy?\n",
      "unknown (5.92 - 6.24): Well,\n",
      "speaker_0 (6.24 - 8.8): it wasn't on my mind right now. It is now.\n",
      "speaker_1 (9.84 - 12.56): Pussy energy drink.\n",
      "unknown (12.96 - 13.84): I see.\n",
      "speaker_0 (14.32 - 14.96): What flavour\n",
      "speaker_1 (15.04 - 18.08): is it? Flavour.\n",
      "speaker_0 (18.48 - 19.28): Leave it.\n",
      "speaker_1 (19.6 - 22.72): Leave it. Yeah, moving on.\n",
      "speaker_0 (22.88 - 35.2): I'd like to introduce something for which, at first, I thought I'm going to struggle to find a motoring application, because what it is is this. This machine is controlled by your iPhone, right? With an app, and it flies up in the air, and there's a camera on it.\n"
     ]
    }
   ],
   "source": [
    "print(prettify_transcript(inference_result['alignment']['words']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed = assign_speakers_by_sentence(inference_result['alignment']['words'], inference_result['alignment']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker_1 (0.4 - 5.28): Ah, now, Rich, would you like some pussy?\n",
      "speaker_0 (5.92 - 8.8): Well, it wasn't on my mind right now. It is now.\n",
      "speaker_1 (9.84 - 12.56): Pussy energy drink.\n",
      "unknown (12.96 - 13.84): I see.\n",
      "speaker_0 (14.32 - 15.52): What flavour is it?\n",
      "speaker_1 (15.68 - 18.08): Flavour.\n",
      "speaker_0 (18.48 - 19.28): Leave it.\n",
      "speaker_1 (19.6 - 22.72): Leave it. Yeah, moving on.\n",
      "speaker_0 (22.88 - 35.2): I'd like to introduce something for which, at first, I thought I'm going to struggle to find a motoring application, because what it is is this. This machine is controlled by your iPhone, right? With an app, and it flies up in the air, and there's a camera on it.\n"
     ]
    }
   ],
   "source": [
    "print(prettify_transcript(fixed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
