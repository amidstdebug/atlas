{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe413600-2eb1-4075-9c86-1a5cbca78103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1cdd6b-e612-4feb-bbd0-c0572381c787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raid/miniconda3/envs/nemo/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from speech_parser import Audio\n",
    "from speech_parser import SileroVAD\n",
    "from speech_parser import OnlineSpeakerClustering\n",
    "from speech_parser import MSDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b890dd4-99b5-4959-93f1-005a62fd8628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9b816c7-db8f-4b42-adb7-efa170cc7dde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-21 14:19:46 cloud:58] Found existing object /home/raid/.cache/torch/NeMo/NeMo_2.1.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
      "[NeMo I 2025-02-21 14:19:46 cloud:64] Re-using file from: /home/raid/.cache/torch/NeMo/NeMo_2.1.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
      "[NeMo I 2025-02-21 14:19:46 common:826] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-21 14:19:48 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    emb_dir: null\n",
      "    sample_rate: 16000\n",
      "    num_spks: 2\n",
      "    soft_label_thres: 0.5\n",
      "    labels: null\n",
      "    batch_size: 15\n",
      "    emb_batch_size: 0\n",
      "    shuffle: true\n",
      "    \n",
      "[NeMo W 2025-02-21 14:19:48 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    emb_dir: null\n",
      "    sample_rate: 16000\n",
      "    num_spks: 2\n",
      "    soft_label_thres: 0.5\n",
      "    labels: null\n",
      "    batch_size: 15\n",
      "    emb_batch_size: 0\n",
      "    shuffle: false\n",
      "    \n",
      "[NeMo W 2025-02-21 14:19:48 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    emb_dir: null\n",
      "    sample_rate: 16000\n",
      "    num_spks: 2\n",
      "    soft_label_thres: 0.5\n",
      "    labels: null\n",
      "    batch_size: 15\n",
      "    emb_batch_size: 0\n",
      "    shuffle: false\n",
      "    seq_eval_mode: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-21 14:19:48 features:305] PADDING: 16\n",
      "[NeMo I 2025-02-21 14:19:48 features:305] PADDING: 16\n",
      "[NeMo I 2025-02-21 14:19:49 save_restore_connector:275] Model EncDecDiarLabelModel was successfully restored from /home/raid/.cache/torch/NeMo/NeMo_2.1.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n"
     ]
    }
   ],
   "source": [
    "msdd = MSDD(\n",
    "    threshold=0.8\n",
    ")\n",
    "titanet_l = msdd.speech_embedding_model\n",
    "vad = SileroVAD(\n",
    "    threshold=0.5\n",
    ")\n",
    "osc = OnlineSpeakerClustering()\n",
    "\n",
    "scales = [1.5, 1.25, 1.0, 0.75, 0.5]\n",
    "hops = [scale/4 for scale in scales]\n",
    "a = Audio(\n",
    "    scales, \n",
    "    hops, \n",
    "    speech_embedding_model=titanet_l,\n",
    "    voice_activity_detection_model=vad,\n",
    "    multi_scale_diarization_model=msdd,\n",
    "    speaker_clustering=osc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03f11f42-78eb-4c32-98a6-90bbc8145ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform, sr = load_audio('test.wav')\n",
    "waveform, sr = load_audio('toefl_eg.mp3')\n",
    "waveform = waveform[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e921416-6557-4d4f-a3e5-31bb9a169bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proba, labels = a(waveform[:500_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2037126f-d0e0-4918-ab7c-d7c7d4b7558e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd5925f-18d4-45d5-ba7c-3951e4416fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proba, labels = a(waveform[500_000:1_000_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "247a64d2-e6ac-4daf-87d8-7dd0320d2aed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proba, labels = a(waveform[1_000_000:4_000_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8e029e6-652b-4198-8ec1-45a685747a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a(waveform[4_000_000:5_000_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "385c26d6-7d74-4f49-8756-d4b72b7f591a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new seg\n",
      "tensor(0.9096, device='cuda:0')\n",
      "17.625\n",
      "new seg\n",
      "tensor(0.8424, device='cuda:0')\n",
      "12.875\n",
      "new seg\n",
      "tensor(0.9019, device='cuda:0')\n",
      "19.125\n",
      "new seg\n",
      "tensor(0.8902, device='cuda:0')\n",
      "11.0\n",
      "new seg\n",
      "tensor(0.6928, device='cuda:0')\n",
      "0.625\n",
      "new seg\n",
      "tensor(0.2580, device='cuda:0')\n",
      "0.5\n",
      "new seg\n",
      "tensor(0.6704, device='cuda:0')\n",
      "0.625\n",
      "new seg\n",
      "tensor(0.2560, device='cuda:0')\n",
      "0.625\n",
      "new seg\n",
      "tensor(0.8220, device='cuda:0')\n",
      "0.5\n",
      "new seg\n",
      "tensor(1., device='cuda:0')\n",
      "0.625\n",
      "new seg\n",
      "tensor(0.9177, device='cuda:0')\n",
      "58.375\n",
      "new seg\n",
      "tensor(0.1373, device='cuda:0')\n",
      "0.75\n",
      "new seg\n",
      "tensor(0.0660, device='cuda:0')\n",
      "0.5\n",
      "new seg\n",
      "tensor(1., device='cuda:0')\n",
      "0.5\n",
      "new seg\n",
      "tensor(0.8224, device='cuda:0')\n",
      "14.125\n",
      "new seg\n",
      "tensor(0.7845, device='cuda:0')\n",
      "2.125\n",
      "new seg\n",
      "tensor(0.7882, device='cuda:0')\n",
      "4.75\n",
      "new seg\n",
      "tensor(0.7888, device='cuda:0')\n",
      "4.625\n",
      "new seg\n",
      "tensor(0.7618, device='cuda:0')\n",
      "10.25\n",
      "new seg\n",
      "tensor(0.3724, device='cuda:0')\n",
      "1.375\n",
      "new seg\n",
      "tensor(0.7200, device='cuda:0')\n",
      "2.75\n",
      "new seg\n",
      "tensor(0.4208, device='cuda:0')\n",
      "0.625\n",
      "new seg\n",
      "tensor(0.8321, device='cuda:0')\n",
      "10.625\n",
      "new seg\n",
      "tensor(1., device='cuda:0')\n",
      "1.0\n",
      "new seg\n",
      "tensor(0.5164, device='cuda:0')\n",
      "1.125\n",
      "new seg\n",
      "tensor(0.8429, device='cuda:0')\n",
      "10.25\n",
      "new seg\n",
      "tensor(0.5407, device='cuda:0')\n",
      "2.125\n",
      "new seg\n",
      "tensor(0.3840, device='cuda:0')\n",
      "1.25\n",
      "new seg\n",
      "tensor(0.4189, device='cuda:0')\n",
      "1.375\n",
      "new seg\n",
      "tensor(0.7509, device='cuda:0')\n",
      "5.625\n",
      "new seg\n",
      "tensor(0.6493, device='cuda:0')\n",
      "0.75\n",
      "new seg\n",
      "tensor(0.7990, device='cuda:0')\n",
      "4.125\n",
      "new seg\n",
      "tensor(0.1180, device='cuda:0')\n",
      "0.5\n",
      "new seg\n",
      "tensor(0.8287, device='cuda:0')\n",
      "6.0\n",
      "new seg\n",
      "tensor(0.2520, device='cuda:0')\n",
      "0.5\n",
      "new seg\n",
      "tensor(0.5020, device='cuda:0')\n",
      "0.5\n",
      "new seg\n",
      "tensor(0.7676, device='cuda:0')\n",
      "10.625\n",
      "new seg\n",
      "tensor(0.8057, device='cuda:0')\n",
      "9.0\n",
      "new seg\n",
      "tensor(0.7310, device='cuda:0')\n",
      "5.25\n",
      "new seg\n",
      "tensor(0.0960, device='cuda:0')\n",
      "0.5\n",
      "new seg\n",
      "tensor(0.2400, device='cuda:0')\n",
      "0.5\n",
      "new seg\n",
      "tensor(0.8059, device='cuda:0')\n",
      "9.375\n",
      "new seg\n",
      "tensor(0.7591, device='cuda:0')\n",
      "6.375\n",
      "new seg\n",
      "tensor(0.2600, device='cuda:0')\n",
      "0.5\n",
      "new seg\n",
      "tensor(0.8291, device='cuda:0')\n",
      "8.625\n",
      "new seg\n",
      "tensor(0.8987, device='cuda:0')\n",
      "5.875\n"
     ]
    }
   ],
   "source": [
    "merged = a.get_merged_speaker_segments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2db251b8-7aad-40ca-a0f7-563387a549de",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.max_silence_per_segment_pct = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c6fa5cf8-b9a1-4d84-bd44-d5ef843cd6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[17.625,\n",
       " 12.875,\n",
       " 19.125,\n",
       " 11.0,\n",
       " 58.375,\n",
       " 14.125,\n",
       " 2.125,\n",
       " 4.75,\n",
       " 4.625,\n",
       " 10.25,\n",
       " 2.75,\n",
       " 10.625,\n",
       " 1.0,\n",
       " 1.125,\n",
       " 10.25,\n",
       " 2.125,\n",
       " 5.625,\n",
       " 4.125,\n",
       " 6.0,\n",
       " 10.625,\n",
       " 9.0,\n",
       " 5.25,\n",
       " 9.375,\n",
       " 6.375,\n",
       " 8.625,\n",
       " 5.875]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.duration for s in merged]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebb7c0b0-edb6-4732-97e7-c8378ad2f1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SpeakerSegment(start=0, end=17.625, data=tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.0015, -0.0009, -0.0007],\n",
       "        device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=17.875, end=30.75, data=tensor([-0.0037, -0.0012,  0.0005,  ...,  0.0074,  0.0059,  0.0018],\n",
       "        device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=31.25, end=50.375, data=tensor([0.0137, 0.0135, 0.0104,  ..., 0.0037, 0.0032, 0.0023], device='cuda:0'), mask=tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=50.875, end=61.875, data=tensor([ 1.6737e-03,  3.6514e-04, -5.9805e-05,  ..., -1.1843e-03,\n",
       "         -1.0885e-03, -7.7725e-04], device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=62.5, end=120.875, data=tensor([-1.6446e-02, -2.6662e-02,  3.6196e-03,  ..., -1.7853e-04,\n",
       "         -2.3472e-04, -6.6784e-05], device='cuda:0'), mask=tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=120.625, end=134.75, data=tensor([-0.0001, -0.0016, -0.0022,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=136.25, end=138.375, data=tensor([ 1.0500e-04,  3.5520e-05, -9.4904e-07,  ...,  3.5779e-02,\n",
       "          2.5473e-02, -1.5061e-02], device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=136.25, end=141.0, data=tensor([ 1.0500e-04,  3.5520e-05, -9.4904e-07,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00], device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=141.25, end=145.875, data=tensor([0.0000, 0.0000, 0.0000,  ..., 0.0001, 0.0001, 0.0001], device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=145.875, end=156.125, data=tensor([0.0001, 0.0002, 0.0001,  ..., 0.0000, 0.0000, 0.0000], device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=157.25, end=160.0, data=tensor([-2.6874e-05,  4.8968e-05,  4.4306e-05,  ..., -1.0536e-01,\n",
       "         -4.4387e-02,  1.0276e-04], device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=159.5, end=170.125, data=tensor([ 0.0007,  0.0007,  0.0006,  ...,  0.0022, -0.0089, -0.0273],\n",
       "        device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=171.625, end=172.625, data=tensor([-0.0116, -0.0216, -0.0344,  ...,  0.0405,  0.0451,  0.0465],\n",
       "        device='cuda:0'), mask=tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=175.5, end=176.625, data=tensor([-0.0270,  0.0102,  0.0398,  ..., -0.0352, -0.0375, -0.0390],\n",
       "        device='cuda:0'), mask=tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=168.75, end=179.0, data=tensor([-8.9835e-05, -1.0205e-04, -6.6433e-05,  ..., -7.3732e-02,\n",
       "         -5.8260e-02, -1.3655e-02], device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=178.375, end=180.5, data=tensor([ 1.4243e-02,  1.3682e-02,  1.3091e-02,  ...,  3.3073e-04,\n",
       "          1.3011e-05, -8.4610e-05], device='cuda:0'), mask=tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=182.5, end=188.125, data=tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.2213e-05,\n",
       "          3.2645e-05, -1.7882e-07], device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=188.0, end=192.125, data=tensor([-7.9522e-05, -6.6163e-05, -8.6511e-05,  ...,  3.0467e-06,\n",
       "         -2.6407e-06, -3.0603e-05], device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=192.0, end=198.0, data=tensor([ 2.2082e-05,  4.5894e-06, -6.2505e-07,  ..., -2.0912e-02,\n",
       "         -2.0819e-02,  8.1124e-03], device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=197.0, end=207.625, data=tensor([-0.0008, -0.0008, -0.0014,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        device='cuda:0'), mask=tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=207.375, end=216.375, data=tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.0842, -0.0760, -0.0607],\n",
       "        device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=215.75, end=221.0, data=tensor([-7.2389e-03, -5.2507e-03, -2.9456e-03,  ...,  6.4661e-07,\n",
       "          5.1318e-07,  7.4244e-08], device='cuda:0'), mask=tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=221.0, end=230.375, data=tensor([-2.1241e-08,  2.0710e-07, -3.6155e-08,  ..., -7.8749e-03,\n",
       "         -1.7725e-01, -3.7701e-02], device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 1., 1., 1.], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=229.5, end=235.875, data=tensor([-0.0115, -0.0075, -0.0342,  ..., -0.1206, -0.1139, -0.1085],\n",
       "        device='cuda:0'), mask=tensor([1., 1., 1.,  ..., 1., 1., 1.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=235.125, end=243.75, data=tensor([-0.0002, -0.0002, -0.0002,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        device='cuda:0'), mask=tensor([1., 1., 1.,  ..., 0., 0., 0.], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=243.5, end=249.375, data=tensor([-6.6372e-12,  2.5448e-12, -8.5143e-12,  ..., -8.6468e-09,\n",
       "         -1.1264e-08, -1.4752e-08], device='cuda:0'), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=1, transcription=None)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0b7ca19b-103a-455d-b670-2987d396b8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 13\n",
    "torchaudio.save('segmented.wav', merged[i].data.unsqueeze(0).cpu(), 16_000)\n",
    "merged[i].speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "976395de-af9c-4cfd-bf50-0490f8f93343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.125"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[i].duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff5d6312-e33b-4ccb-ac12-7ab7d3b5aace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7168., device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.base_scale_segments[1].mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "307f2f0c-f5ac-4763-b46e-35842a013bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech_parser.audio import SpeakerSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "63c22ced-61c0-4140-8e09-443a96d64a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16_000\n",
    "\n",
    "def merge_segments(segments, speaker, sampling_rate=16000):\n",
    "    \n",
    "    first_segment = segments[0]\n",
    "    start = first_segment.start\n",
    "    end = first_segment.start\n",
    "    normal_segment_duration = first_segment.end - first_segment.start\n",
    "    waveforms = []\n",
    "    \n",
    "    for segment in segments:\n",
    "        increment = segment.end - end\n",
    "        assert increment <= normal_segment_duration, f\"Issue in the matching section of get_merged_speaker_segments(), {increment} > {normal_segment_duration}\"\n",
    "\n",
    "        concat_length = int(increment*sampling_rate)\n",
    "        waveforms.append(segment.data[-concat_length:])\n",
    "        \n",
    "        end = segment.end\n",
    "        \n",
    "    waveform = torch.cat(waveforms)\n",
    "    return SpeakerSegment(start, end, waveform, speaker)\n",
    "    # print([segment.start for segment in segments])\n",
    "    # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04a760d7-b394-45e7-862b-6ddb25d60367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8000])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "295996a7-f2c4-4b53-be8e-180558e9710a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "active_speakers  = {}\n",
    "\n",
    "merged_segments = []\n",
    "\n",
    "for segment in a.base_scale_segments:\n",
    "    curr_active_speakers = list(active_speakers.items())\n",
    "    for speaker, active_segments in curr_active_speakers:\n",
    "        # end the speaker segment if the start of the new segment is past the end of the old\n",
    "        if (speaker in segment.speakers) and (segment.start <= active_segments[-1].end):\n",
    "            active_speakers[speaker].append(segment)\n",
    "        else:\n",
    "            # merge and end speakers\n",
    "            merged_segments.append(merge_segments(active_segments, speaker))\n",
    "            active_speakers.pop(speaker)\n",
    "        \n",
    "    for speaker in segment.speakers:\n",
    "        if speaker not in active_speakers:\n",
    "            # start speaker\n",
    "            active_speakers[speaker] = [segment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5d6ea473-af5a-4f14-bbbb-59ebad40d8dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SpeakerSegment(start=62.5, end=120.75, data=tensor([-0.0164, -0.0267,  0.0036,  ..., -0.0011, -0.0012, -0.0008],\n",
       "        device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=120.75, end=134.75, data=tensor([-0.0006, -0.0006, -0.0004,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=136.25, end=138.5, data=tensor([ 1.0500e-04,  3.5520e-05, -9.4904e-07,  ..., -1.4732e-02,\n",
       "         -1.2964e-02, -1.2140e-02], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=136.25, end=141.0, data=tensor([ 1.0500e-04,  3.5520e-05, -9.4904e-07,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=141.25, end=145.75, data=tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -7.6305e-05,\n",
       "         -5.3419e-05, -3.3926e-05], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=146.0, end=156.0, data=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=156.0, end=157.25, data=tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.2885e-05,\n",
       "         -1.2899e-04, -1.2129e-04], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=157.25, end=160.75, data=tensor([-2.6874e-05,  4.8968e-05,  4.4306e-05,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=159.5, end=169.5, data=tensor([0.0007, 0.0007, 0.0006,  ..., 0.0028, 0.0056, 0.0049], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=172.25, end=173.5, data=tensor([ 0.0203,  0.0203,  0.0234,  ..., -0.0372, -0.0215, -0.0152],\n",
       "        device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=175.75, end=176.5, data=tensor([-2.4743e-07, -8.0860e-08, -1.4174e-07,  ...,  1.9525e-03,\n",
       "         -1.7611e-03,  2.3732e-04], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=169.0, end=179.0, data=tensor([-1.4334e-07,  6.6419e-07, -6.3802e-07,  ..., -7.3732e-02,\n",
       "         -5.8260e-02, -1.3655e-02], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=178.5, end=182.5, data=tensor([-3.8050e-05, -6.3207e-06, -1.4694e-05,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=182.5, end=188.0, data=tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.0001, -0.0002, -0.0001],\n",
       "        device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=188.0, end=192.0, data=tensor([-7.9522e-05, -6.6163e-05, -8.6511e-05,  ...,  1.0326e-04,\n",
       "          5.8267e-05,  6.1283e-05], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=191.5, end=192.0, data=tensor([1.3016e-02, 1.4583e-02, 1.4826e-02,  ..., 1.0326e-04, 5.8267e-05,\n",
       "         6.1283e-05], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=192.0, end=192.5, data=tensor([ 2.2082e-05,  4.5894e-06, -6.2505e-07,  ..., -7.1008e-02,\n",
       "         -6.8520e-02, -6.5419e-02], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=192.0, end=197.75, data=tensor([ 2.2082e-05,  4.5894e-06, -6.2505e-07,  ...,  2.8127e-01,\n",
       "          1.7621e-01,  4.8635e-02], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=197.0, end=207.5, data=tensor([-0.0008, -0.0008, -0.0014,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=207.5, end=216.5, data=tensor([ 0.0000,  0.0000,  0.0000,  ...,  0.0102, -0.0265, -0.0531],\n",
       "        device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=215.75, end=221.0, data=tensor([-7.2389e-03, -5.2507e-03, -2.9456e-03,  ...,  6.4661e-07,\n",
       "          5.1318e-07,  7.4244e-08], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=221.0, end=221.5, data=tensor([-2.1241e-08,  2.0710e-07, -3.6155e-08,  ..., -1.8223e-01,\n",
       "         -2.0810e-01, -1.8929e-01], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=221.0, end=230.5, data=tensor([-2.1241e-08,  2.0710e-07, -3.6155e-08,  ..., -3.0790e-02,\n",
       "          5.9832e-02,  1.9181e-01], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=230.0, end=235.75, data=tensor([-5.8362e-05, -5.8233e-05, -7.1750e-05,  ...,  2.9137e-01,\n",
       "          2.7412e-01,  2.5115e-01], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=235.25, end=249.75, data=tensor([ 3.2089e-05,  1.9223e-05,  1.6009e-06,  ..., -1.4414e-15,\n",
       "         -1.5969e-15, -1.7658e-15], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=250.0, end=254.25, data=tensor([ 0.1177,  0.0553,  0.0043,  ..., -0.0002, -0.0002, -0.0003],\n",
       "        device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=253.75, end=258.75, data=tensor([-4.8572e-08, -2.0561e-05, -8.9008e-06,  ..., -8.3839e-05,\n",
       "         -1.2448e-04, -8.9330e-05], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=258.5, end=274.75, data=tensor([-8.2369e-05, -8.9729e-05, -9.1564e-05,  ..., -7.3750e-02,\n",
       "         -5.1632e-02, -2.4496e-02], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=274.0, end=284.0, data=tensor([-1.0222e-02, -5.7292e-03, -1.7429e-02,  ..., -1.3761e-05,\n",
       "         -2.5257e-06, -1.0457e-05], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=284.0, end=284.5, data=tensor([ 3.3601e-06,  2.0928e-05,  4.8903e-06,  ..., -1.2895e-03,\n",
       "          6.0876e-04, -2.2165e-03], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=284.0, end=292.5, data=tensor([ 3.3601e-06,  2.0928e-05,  4.8903e-06,  ..., -9.0860e-02,\n",
       "         -8.8710e-02, -8.3112e-02], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=292.25, end=295.25, data=tensor([-4.7058e-06, -7.2782e-06,  1.1720e-07,  ...,  2.0162e-05,\n",
       "          5.9449e-05,  6.3034e-06], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=294.75, end=305.25, data=tensor([ 0.0007,  0.0006,  0.0008,  ..., -0.0040, -0.0055, -0.0072],\n",
       "        device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=305.0, end=312.25, data=tensor([-2.8620e-06, -2.6328e-05, -3.5366e-05,  ...,  6.8589e-06,\n",
       "          2.8502e-06, -2.2640e-06], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=312.5, end=324.25, data=tensor([-9.5128e-05, -7.0577e-05, -7.0041e-05,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=325.5, end=328.75, data=tensor([0.0010, 0.0010, 0.0010,  ..., 0.0031, 0.0034, 0.0029], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=325.75, end=328.75, data=tensor([-0.0030, -0.0030, -0.0028,  ...,  0.0031,  0.0034,  0.0029],\n",
       "        device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=354.25, end=355.5, data=tensor([0.0000, 0.0000, 0.0000,  ..., 0.0365, 0.0428, 0.0479], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=354.25, end=360.75, data=tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.7843e-18,\n",
       "          8.4065e-17, -1.4272e-17], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=384.25, end=388.0, data=tensor([1.3542e-06, 1.3099e-06, 1.3898e-06,  ..., 1.9312e-03, 1.8659e-03,\n",
       "         1.6952e-03], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=414.0, end=420.5, data=tensor([-0.0003, -0.0005, -0.0006,  ...,  0.0017,  0.0018,  0.0020],\n",
       "        device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=443.5, end=448.25, data=tensor([0.0000, 0.0000, 0.0000,  ..., 0.0004, 0.0004, 0.0004], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=445.5, end=456.25, data=tensor([-3.6142e-02, -5.1562e-02, -6.2405e-02,  ..., -1.2034e-08,\n",
       "          1.1610e-08, -5.7967e-09], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=456.25, end=461.0, data=tensor([-2.9490e-09,  2.8441e-09, -2.2450e-09,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=461.0, end=463.0, data=tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.0518e-05,\n",
       "         -3.0218e-06, -4.8026e-07], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=463.25, end=464.0, data=tensor([ 3.7538e-06, -9.7592e-07,  9.4208e-07,  ...,  3.2053e-03,\n",
       "          3.1729e-03,  3.1985e-03], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=464.0, end=466.0, data=tensor([3.8616e-03, 3.7273e-03, 2.8335e-03,  ..., 2.8540e-05, 4.3866e-05,\n",
       "         3.8670e-05], device='cuda:0'), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=463.25, end=473.0, data=tensor([ 3.7538e-06, -9.7592e-07,  9.4208e-07,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00], device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=503.25, end=507.0, data=tensor([-0.0001, -0.0001, -0.0001,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=507.5, end=508.0, data=tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.1063, -0.0710, -0.0395],\n",
       "        device='cuda:0'), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=507.5, end=518.25, data=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=518.25, end=524.25, data=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=524.5, end=529.5, data=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=529.5, end=542.5, data=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=542.75, end=579.75, data=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=579.75, end=582.25, data=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=582.25, end=590.0, data=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=590.0, end=592.5, data=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=592.5, end=607.5, data=tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0'), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=607.5, end=624.75, data=tensor([0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.5411e-05, 1.0687e-04,\n",
       "         2.0200e-04], device='cuda:0'), speaker=2, transcription=None)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4a3217b-ff2d-4e4a-8f36-89800344abf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4973, device='cuda:0')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_segments[-2].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e772f0b-869a-4e07-a948-30966824bc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590ed1cb-114e-49ae-838b-2d9cb2868b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 0: 62.00s - 120.00s (duration: 58.00s)\n",
      "Speaker 0: 120.25s - 134.00s (duration: 13.75s)\n",
      "Speaker 0: 135.75s - 137.75s (duration: 2.00s)\n",
      "Speaker 1: 135.75s - 140.25s (duration: 4.50s)\n",
      "Speaker 1: 140.75s - 145.00s (duration: 4.25s)\n",
      "Speaker 2: 145.50s - 155.25s (duration: 9.75s)\n",
      "Speaker 2: 155.50s - 156.50s (duration: 1.00s)\n",
      "Speaker 1: 156.75s - 160.00s (duration: 3.25s)\n",
      "Speaker 2: 159.00s - 168.75s (duration: 9.75s)\n",
      "Speaker 1: 168.50s - 178.25s (duration: 9.75s)\n",
      "Speaker 2: 171.75s - 172.75s (duration: 1.00s)\n",
      "Speaker 2: 175.25s - 175.75s (duration: 0.50s)\n",
      "Speaker 2: 178.00s - 181.75s (duration: 3.75s)\n",
      "Speaker 2: 182.00s - 187.25s (duration: 5.25s)\n",
      "Speaker 1: 187.50s - 191.25s (duration: 3.75s)\n",
      "Speaker 2: 191.00s - 191.25s (duration: 0.25s)\n",
      "Speaker 1: 191.50s - 191.75s (duration: 0.25s)\n",
      "Speaker 2: 191.50s - 197.00s (duration: 5.50s)\n",
      "Speaker 1: 196.50s - 206.75s (duration: 10.25s)\n",
      "Speaker 1: 207.00s - 215.75s (duration: 8.75s)\n",
      "Speaker 2: 215.25s - 220.25s (duration: 5.00s)\n",
      "Speaker 1: 220.50s - 229.75s (duration: 9.25s)\n",
      "Speaker 2: 220.50s - 220.75s (duration: 0.25s)\n",
      "Speaker 2: 229.50s - 235.00s (duration: 5.50s)\n",
      "Speaker 1: 234.75s - 249.00s (duration: 14.25s)\n",
      "Speaker 1: 249.25s - 253.25s (duration: 4.00s)\n",
      "Speaker 2: 253.00s - 257.75s (duration: 4.75s)\n",
      "Speaker 1: 257.75s - 273.75s (duration: 16.00s)\n",
      "Speaker 2: 273.25s - 283.00s (duration: 9.75s)\n",
      "Speaker 1: 283.25s - 291.50s (duration: 8.25s)\n",
      "Speaker 2: 283.25s - 283.50s (duration: 0.25s)\n",
      "Speaker 2: 291.50s - 294.25s (duration: 2.75s)\n",
      "Speaker 1: 294.00s - 304.25s (duration: 10.25s)\n",
      "Speaker 2: 304.25s - 311.25s (duration: 7.00s)\n",
      "Speaker 1: 311.75s - 323.25s (duration: 11.50s)\n",
      "Speaker 0: 324.75s - 327.75s (duration: 3.00s)\n",
      "Speaker 1: 325.00s - 327.75s (duration: 2.75s)\n",
      "Speaker 0: 353.50s - 359.75s (duration: 6.25s)\n",
      "Speaker 1: 353.50s - 354.50s (duration: 1.00s)\n",
      "Speaker 0: 383.50s - 387.00s (duration: 3.50s)\n",
      "Speaker 0: 413.25s - 419.50s (duration: 6.25s)\n",
      "Speaker 0: 442.75s - 447.25s (duration: 4.50s)\n",
      "Speaker 1: 444.75s - 455.25s (duration: 10.50s)\n",
      "Speaker 1: 455.50s - 460.00s (duration: 4.50s)\n",
      "Speaker 1: 460.25s - 462.00s (duration: 1.75s)\n",
      "Speaker 0: 462.50s - 463.00s (duration: 0.50s)\n",
      "Speaker 1: 462.50s - 472.00s (duration: 9.50s)\n",
      "Speaker 0: 463.25s - 465.00s (duration: 1.75s)\n",
      "Speaker 1: 502.50s - 506.00s (duration: 3.50s)\n",
      "Speaker 1: 506.75s - 507.00s (duration: 0.25s)\n",
      "Speaker 2: 506.75s - 517.25s (duration: 10.50s)\n",
      "Speaker 2: 517.50s - 523.25s (duration: 5.75s)\n",
      "Speaker 2: 523.75s - 528.50s (duration: 4.75s)\n",
      "Speaker 2: 528.75s - 541.50s (duration: 12.75s)\n",
      "Speaker 2: 542.00s - 578.75s (duration: 36.75s)\n",
      "Speaker 2: 579.00s - 581.25s (duration: 2.25s)\n",
      "Speaker 2: 581.50s - 589.00s (duration: 7.50s)\n",
      "Speaker 2: 589.25s - 591.50s (duration: 2.25s)\n",
      "Speaker 2: 591.75s - 606.50s (duration: 14.75s)\n",
      "Speaker 2: 606.75s - 623.75s (duration: 17.00s)\n"
     ]
    }
   ],
   "source": [
    "def process_timeline(data):\n",
    "    # Convert None to empty list for consistency\n",
    "    timeline = [[] if x is None else sorted(x) for x in data]\n",
    "    return timeline\n",
    "\n",
    "def merge_segments(timeline):\n",
    "    merged_segments = []\n",
    "    \n",
    "    # Find continuous segments for each speaker\n",
    "    for speaker in set([spk for t in timeline for spk in t]):\n",
    "        start_idx = None\n",
    "        \n",
    "        for t, speakers in enumerate(timeline):\n",
    "            if speaker in speakers:\n",
    "                if start_idx is None:\n",
    "                    start_idx = t\n",
    "            elif start_idx is not None:\n",
    "                # Add segment\n",
    "                merged_segments.append({\n",
    "                    'speaker': speaker,\n",
    "                    'start': start_idx * 0.25,  # Convert to seconds\n",
    "                    'end': t * 0.25,            # Convert to seconds\n",
    "                    'duration': (t - start_idx) * 0.25\n",
    "                })\n",
    "                start_idx = None\n",
    "        \n",
    "        # Handle segment that goes until the end\n",
    "        if start_idx is not None:\n",
    "            merged_segments.append({\n",
    "                'speaker': speaker,\n",
    "                'start': start_idx * 0.25,\n",
    "                'end': len(timeline) * 0.25,\n",
    "                'duration': (len(timeline) - start_idx) * 0.25\n",
    "            })\n",
    "    \n",
    "    return sorted(merged_segments, key=lambda x: (x['start'], x['speaker']))\n",
    "\n",
    "def generate_rttm(segments):\n",
    "    rttm_lines = []\n",
    "    \n",
    "    for seg in segments:\n",
    "        rttm_line = f\"SPEAKER unknown 1 {seg['start']:.3f} {seg['duration']:.3f} <NA> <NA> SPEAKER_{seg['speaker']} <NA> <NA>\"\n",
    "        rttm_lines.append(rttm_line)\n",
    "    \n",
    "    return \"\\n\".join(rttm_lines)\n",
    "\n",
    "def create_visualization(segments, total_duration):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    \n",
    "    # Get unique speakers and assign them y-coordinates\n",
    "    unique_speakers = sorted(set(seg['speaker'] for seg in segments))\n",
    "    speaker_to_y = {speaker: i for i, speaker in enumerate(unique_speakers)}\n",
    "    \n",
    "    # Create line segments for each speaker\n",
    "    for speaker in unique_speakers:\n",
    "        speaker_segments = [seg for seg in segments if seg['speaker'] == speaker]\n",
    "        \n",
    "        for seg in speaker_segments:\n",
    "            plt.hlines(\n",
    "                y=speaker_to_y[seg['speaker']],\n",
    "                xmin=seg['start'],\n",
    "                xmax=seg['end'],\n",
    "                linewidth=4,\n",
    "                label=f\"Speaker {speaker}\"\n",
    "            )\n",
    "    \n",
    "    # Set axis limits to show the full timeline\n",
    "    plt.xlim(0, total_duration)\n",
    "    plt.ylim(-0.5, len(unique_speakers) - 0.5)\n",
    "    \n",
    "    # Set y-axis labels\n",
    "    plt.yticks(\n",
    "        range(len(unique_speakers)),\n",
    "        [f\"Speaker {speaker}\" for speaker in unique_speakers]\n",
    "    )\n",
    "    \n",
    "    # Remove duplicate labels in legend\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(), loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Speakers\")\n",
    "    plt.title(\"Speaker Diarization Timeline\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add some padding to the plot\n",
    "    plt.margins(x=0.02)\n",
    "    \n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig('speaker_diarization.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Use your existing code to process the data and generate segments\n",
    "timeline = process_timeline(timeline)\n",
    "merged_segments = merge_segments(timeline)\n",
    "\n",
    "# Calculate total duration in seconds\n",
    "total_duration = len(timeline) * 0.25\n",
    "\n",
    "# Generate RTTM\n",
    "rttm_content = generate_rttm(merged_segments)\n",
    "with open('output.rttm', 'w') as f:\n",
    "    f.write(rttm_content)\n",
    "\n",
    "# Create visualization with total duration\n",
    "create_visualization(merged_segments, total_duration)\n",
    "\n",
    "# Print segments for verification\n",
    "for seg in merged_segments:\n",
    "    print(f\"Speaker {seg['speaker']}: {seg['start']:.2f}s - {seg['end']:.2f}s (duration: {seg['duration']:.2f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b30a9-a069-489c-8b8a-d7796b7fdc07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
