{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe413600-2eb1-4075-9c86-1a5cbca78103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc1cdd6b-e612-4feb-bbd0-c0572381c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diarizer import Audio\n",
    "from diarizer import SileroVAD\n",
    "from diarizer import OnlineSpeakerClustering\n",
    "from diarizer import MSDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b890dd4-99b5-4959-93f1-005a62fd8628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a6bce09-ae51-496e-9ab1-94e2f1dcc849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-20 21:29:10 cloud:58] Found existing object /home/raid/.cache/torch/NeMo/NeMo_2.1.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
      "[NeMo I 2025-02-20 21:29:10 cloud:64] Re-using file from: /home/raid/.cache/torch/NeMo/NeMo_2.1.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
      "[NeMo I 2025-02-20 21:29:10 common:826] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-20 21:29:11 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    emb_dir: null\n",
      "    sample_rate: 16000\n",
      "    num_spks: 2\n",
      "    soft_label_thres: 0.5\n",
      "    labels: null\n",
      "    batch_size: 15\n",
      "    emb_batch_size: 0\n",
      "    shuffle: true\n",
      "    \n",
      "[NeMo W 2025-02-20 21:29:11 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    emb_dir: null\n",
      "    sample_rate: 16000\n",
      "    num_spks: 2\n",
      "    soft_label_thres: 0.5\n",
      "    labels: null\n",
      "    batch_size: 15\n",
      "    emb_batch_size: 0\n",
      "    shuffle: false\n",
      "    \n",
      "[NeMo W 2025-02-20 21:29:11 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    emb_dir: null\n",
      "    sample_rate: 16000\n",
      "    num_spks: 2\n",
      "    soft_label_thres: 0.5\n",
      "    labels: null\n",
      "    batch_size: 15\n",
      "    emb_batch_size: 0\n",
      "    shuffle: false\n",
      "    seq_eval_mode: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-20 21:29:11 features:305] PADDING: 16\n",
      "[NeMo I 2025-02-20 21:29:12 features:305] PADDING: 16\n",
      "[NeMo I 2025-02-20 21:29:12 save_restore_connector:275] Model EncDecDiarLabelModel was successfully restored from /home/raid/.cache/torch/NeMo/NeMo_2.1.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n"
     ]
    }
   ],
   "source": [
    "msdd = MSDD(\n",
    "    threshold=0.8\n",
    ")\n",
    "titanet_l = msdd.speech_embedding_model\n",
    "vad = SileroVAD(\n",
    "    threshold=0.5\n",
    ")\n",
    "osc = OnlineSpeakerClustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b816c7-db8f-4b42-adb7-efa170cc7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [1.5, 1.25, 1.0, 0.75, 0.5]\n",
    "hops = [0.75, 0.625, 0.5, 0.375, 0.25]\n",
    "a = Audio(\n",
    "    scales, \n",
    "    hops, \n",
    "    speech_embedding_model=titanet_l,\n",
    "    voice_activity_detection_model=vad,\n",
    "    multi_scale_diarization_model=msdd,\n",
    "    speaker_clustering=osc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03f11f42-78eb-4c32-98a6-90bbc8145ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform, sr = load_audio('test.wav')\n",
    "waveform, sr = load_audio('toefl_eg.mp3')\n",
    "waveform = waveform[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e921416-6557-4d4f-a3e5-31bb9a169bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 192, 1])\n"
     ]
    }
   ],
   "source": [
    "proba, labels = a(waveform[:500_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bd5925f-18d4-45d5-ba7c-3951e4416fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 192, 1])\n"
     ]
    }
   ],
   "source": [
    "proba, labels = a(waveform[500_000:1_000_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "247a64d2-e6ac-4daf-87d8-7dd0320d2aed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 192, 3])\n"
     ]
    }
   ],
   "source": [
    "proba, labels = a(waveform[1_000_000:4_000_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8e029e6-652b-4198-8ec1-45a685747a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 192, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2468, 0.3410, 0.4089,  ..., 0.4451, 0.4427, 0.4259],\n",
       "         [0.9999, 1.0000, 1.0000,  ..., 0.4617, 0.3913, 0.2931],\n",
       "         [0.3836, 0.3176, 0.3007,  ..., 1.0000, 1.0000, 1.0000]],\n",
       "        device='cuda:0'),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 1., 1.]], device='cuda:0'))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(waveform[4_000_000:10_000_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1726a181-c8dc-4826-9b14-ff89d0596ddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timeline = [segment.speakers for segment in a.base_scale_segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590ed1cb-114e-49ae-838b-2d9cb2868b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 0: 62.00s - 120.00s (duration: 58.00s)\n",
      "Speaker 0: 120.25s - 134.00s (duration: 13.75s)\n",
      "Speaker 0: 135.75s - 137.75s (duration: 2.00s)\n",
      "Speaker 1: 135.75s - 140.25s (duration: 4.50s)\n",
      "Speaker 1: 140.75s - 145.00s (duration: 4.25s)\n",
      "Speaker 2: 145.50s - 155.25s (duration: 9.75s)\n",
      "Speaker 2: 155.50s - 156.50s (duration: 1.00s)\n",
      "Speaker 1: 156.75s - 160.00s (duration: 3.25s)\n",
      "Speaker 2: 159.00s - 168.75s (duration: 9.75s)\n",
      "Speaker 1: 168.50s - 178.25s (duration: 9.75s)\n",
      "Speaker 2: 171.75s - 172.75s (duration: 1.00s)\n",
      "Speaker 2: 175.25s - 175.75s (duration: 0.50s)\n",
      "Speaker 2: 178.00s - 181.75s (duration: 3.75s)\n",
      "Speaker 2: 182.00s - 187.25s (duration: 5.25s)\n",
      "Speaker 1: 187.50s - 191.25s (duration: 3.75s)\n",
      "Speaker 2: 191.00s - 191.25s (duration: 0.25s)\n",
      "Speaker 1: 191.50s - 191.75s (duration: 0.25s)\n",
      "Speaker 2: 191.50s - 197.00s (duration: 5.50s)\n",
      "Speaker 1: 196.50s - 206.75s (duration: 10.25s)\n",
      "Speaker 1: 207.00s - 215.75s (duration: 8.75s)\n",
      "Speaker 2: 215.25s - 220.25s (duration: 5.00s)\n",
      "Speaker 1: 220.50s - 229.75s (duration: 9.25s)\n",
      "Speaker 2: 220.50s - 220.75s (duration: 0.25s)\n",
      "Speaker 2: 229.50s - 235.00s (duration: 5.50s)\n",
      "Speaker 1: 234.75s - 249.00s (duration: 14.25s)\n",
      "Speaker 1: 249.25s - 253.25s (duration: 4.00s)\n",
      "Speaker 2: 253.00s - 257.75s (duration: 4.75s)\n",
      "Speaker 1: 257.75s - 273.75s (duration: 16.00s)\n",
      "Speaker 2: 273.25s - 283.00s (duration: 9.75s)\n",
      "Speaker 1: 283.25s - 291.50s (duration: 8.25s)\n",
      "Speaker 2: 283.25s - 283.50s (duration: 0.25s)\n",
      "Speaker 2: 291.50s - 294.25s (duration: 2.75s)\n",
      "Speaker 1: 294.00s - 304.25s (duration: 10.25s)\n",
      "Speaker 2: 304.25s - 311.25s (duration: 7.00s)\n",
      "Speaker 1: 311.75s - 323.25s (duration: 11.50s)\n",
      "Speaker 0: 324.75s - 327.75s (duration: 3.00s)\n",
      "Speaker 1: 325.00s - 327.75s (duration: 2.75s)\n",
      "Speaker 0: 353.50s - 359.75s (duration: 6.25s)\n",
      "Speaker 1: 353.50s - 354.50s (duration: 1.00s)\n",
      "Speaker 0: 383.50s - 387.00s (duration: 3.50s)\n",
      "Speaker 0: 413.25s - 419.50s (duration: 6.25s)\n",
      "Speaker 0: 442.75s - 447.25s (duration: 4.50s)\n",
      "Speaker 1: 444.75s - 455.25s (duration: 10.50s)\n",
      "Speaker 1: 455.50s - 460.00s (duration: 4.50s)\n",
      "Speaker 1: 460.25s - 462.00s (duration: 1.75s)\n",
      "Speaker 0: 462.50s - 463.00s (duration: 0.50s)\n",
      "Speaker 1: 462.50s - 472.00s (duration: 9.50s)\n",
      "Speaker 0: 463.25s - 465.00s (duration: 1.75s)\n",
      "Speaker 1: 502.50s - 506.00s (duration: 3.50s)\n",
      "Speaker 1: 506.75s - 507.00s (duration: 0.25s)\n",
      "Speaker 2: 506.75s - 517.25s (duration: 10.50s)\n",
      "Speaker 2: 517.50s - 523.25s (duration: 5.75s)\n",
      "Speaker 2: 523.75s - 528.50s (duration: 4.75s)\n",
      "Speaker 2: 528.75s - 541.50s (duration: 12.75s)\n",
      "Speaker 2: 542.00s - 578.75s (duration: 36.75s)\n",
      "Speaker 2: 579.00s - 581.25s (duration: 2.25s)\n",
      "Speaker 2: 581.50s - 589.00s (duration: 7.50s)\n",
      "Speaker 2: 589.25s - 591.50s (duration: 2.25s)\n",
      "Speaker 2: 591.75s - 606.50s (duration: 14.75s)\n",
      "Speaker 2: 606.75s - 623.75s (duration: 17.00s)\n"
     ]
    }
   ],
   "source": [
    "def process_timeline(data):\n",
    "    # Convert None to empty list for consistency\n",
    "    timeline = [[] if x is None else sorted(x) for x in data]\n",
    "    return timeline\n",
    "\n",
    "def merge_segments(timeline):\n",
    "    merged_segments = []\n",
    "    \n",
    "    # Find continuous segments for each speaker\n",
    "    for speaker in set([spk for t in timeline for spk in t]):\n",
    "        start_idx = None\n",
    "        \n",
    "        for t, speakers in enumerate(timeline):\n",
    "            if speaker in speakers:\n",
    "                if start_idx is None:\n",
    "                    start_idx = t\n",
    "            elif start_idx is not None:\n",
    "                # Add segment\n",
    "                merged_segments.append({\n",
    "                    'speaker': speaker,\n",
    "                    'start': start_idx * 0.25,  # Convert to seconds\n",
    "                    'end': t * 0.25,            # Convert to seconds\n",
    "                    'duration': (t - start_idx) * 0.25\n",
    "                })\n",
    "                start_idx = None\n",
    "        \n",
    "        # Handle segment that goes until the end\n",
    "        if start_idx is not None:\n",
    "            merged_segments.append({\n",
    "                'speaker': speaker,\n",
    "                'start': start_idx * 0.25,\n",
    "                'end': len(timeline) * 0.25,\n",
    "                'duration': (len(timeline) - start_idx) * 0.25\n",
    "            })\n",
    "    \n",
    "    return sorted(merged_segments, key=lambda x: (x['start'], x['speaker']))\n",
    "\n",
    "def generate_rttm(segments):\n",
    "    rttm_lines = []\n",
    "    \n",
    "    for seg in segments:\n",
    "        rttm_line = f\"SPEAKER unknown 1 {seg['start']:.3f} {seg['duration']:.3f} <NA> <NA> SPEAKER_{seg['speaker']} <NA> <NA>\"\n",
    "        rttm_lines.append(rttm_line)\n",
    "    \n",
    "    return \"\\n\".join(rttm_lines)\n",
    "\n",
    "def create_visualization(segments, total_duration):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    \n",
    "    # Get unique speakers and assign them y-coordinates\n",
    "    unique_speakers = sorted(set(seg['speaker'] for seg in segments))\n",
    "    speaker_to_y = {speaker: i for i, speaker in enumerate(unique_speakers)}\n",
    "    \n",
    "    # Create line segments for each speaker\n",
    "    for speaker in unique_speakers:\n",
    "        speaker_segments = [seg for seg in segments if seg['speaker'] == speaker]\n",
    "        \n",
    "        for seg in speaker_segments:\n",
    "            plt.hlines(\n",
    "                y=speaker_to_y[seg['speaker']],\n",
    "                xmin=seg['start'],\n",
    "                xmax=seg['end'],\n",
    "                linewidth=4,\n",
    "                label=f\"Speaker {speaker}\"\n",
    "            )\n",
    "    \n",
    "    # Set axis limits to show the full timeline\n",
    "    plt.xlim(0, total_duration)\n",
    "    plt.ylim(-0.5, len(unique_speakers) - 0.5)\n",
    "    \n",
    "    # Set y-axis labels\n",
    "    plt.yticks(\n",
    "        range(len(unique_speakers)),\n",
    "        [f\"Speaker {speaker}\" for speaker in unique_speakers]\n",
    "    )\n",
    "    \n",
    "    # Remove duplicate labels in legend\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(), loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Speakers\")\n",
    "    plt.title(\"Speaker Diarization Timeline\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add some padding to the plot\n",
    "    plt.margins(x=0.02)\n",
    "    \n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig('speaker_diarization.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Use your existing code to process the data and generate segments\n",
    "timeline = process_timeline(timeline)\n",
    "merged_segments = merge_segments(timeline)\n",
    "\n",
    "# Calculate total duration in seconds\n",
    "total_duration = len(timeline) * 0.25\n",
    "\n",
    "# Generate RTTM\n",
    "rttm_content = generate_rttm(merged_segments)\n",
    "with open('output.rttm', 'w') as f:\n",
    "    f.write(rttm_content)\n",
    "\n",
    "# Create visualization with total duration\n",
    "create_visualization(merged_segments, total_duration)\n",
    "\n",
    "# Print segments for verification\n",
    "for seg in merged_segments:\n",
    "    print(f\"Speaker {seg['speaker']}: {seg['start']:.2f}s - {seg['end']:.2f}s (duration: {seg['duration']:.2f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b30a9-a069-489c-8b8a-d7796b7fdc07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
