{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe413600-2eb1-4075-9c86-1a5cbca78103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc1cdd6b-e612-4feb-bbd0-c0572381c787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raid/miniconda3/envs/nemo/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from speech_parser import Audio\n",
    "from speech_parser import SileroVAD\n",
    "from speech_parser import OnlineSpeakerClustering\n",
    "from speech_parser import MSDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51d09ee5-7e99-47fa-a7ef-fc7287fc7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0.1, 0.2, 0.3, -0.4, 0.5], [0.1, 0.2, 0.3, -0.4, 0.5], [0.1, 0.2, 0.3, 0, 0.5], [0.1, 0.2, 0.3, -0.4, 0.5], [0.1, 0.2, 0.3, -0.4, 0.5]])\n",
    "y = torch.tensor([1, 2, 3, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "760235aa-40d9-4810-94f0-36360270f417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1400, 0.1400, 0.1800])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_labels = y.unique()\n",
    "\n",
    "torch.stack([x[y == label].mean() for label in unique_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b890dd4-99b5-4959-93f1-005a62fd8628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a6bce09-ae51-496e-9ab1-94e2f1dcc849",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-26 17:19:13 cloud:58] Found existing object /home/raid/.cache/torch/NeMo/NeMo_2.1.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
      "[NeMo I 2025-02-26 17:19:13 cloud:64] Re-using file from: /home/raid/.cache/torch/NeMo/NeMo_2.1.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
      "[NeMo I 2025-02-26 17:19:13 common:826] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-02-26 17:19:15 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    emb_dir: null\n",
      "    sample_rate: 16000\n",
      "    num_spks: 2\n",
      "    soft_label_thres: 0.5\n",
      "    labels: null\n",
      "    batch_size: 15\n",
      "    emb_batch_size: 0\n",
      "    shuffle: true\n",
      "    \n",
      "[NeMo W 2025-02-26 17:19:15 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    emb_dir: null\n",
      "    sample_rate: 16000\n",
      "    num_spks: 2\n",
      "    soft_label_thres: 0.5\n",
      "    labels: null\n",
      "    batch_size: 15\n",
      "    emb_batch_size: 0\n",
      "    shuffle: false\n",
      "    \n",
      "[NeMo W 2025-02-26 17:19:15 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    emb_dir: null\n",
      "    sample_rate: 16000\n",
      "    num_spks: 2\n",
      "    soft_label_thres: 0.5\n",
      "    labels: null\n",
      "    batch_size: 15\n",
      "    emb_batch_size: 0\n",
      "    shuffle: false\n",
      "    seq_eval_mode: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-02-26 17:19:15 features:305] PADDING: 16\n",
      "[NeMo I 2025-02-26 17:19:15 features:305] PADDING: 16\n",
      "[NeMo I 2025-02-26 17:19:16 save_restore_connector:275] Model EncDecDiarLabelModel was successfully restored from /home/raid/.cache/torch/NeMo/NeMo_2.1.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n"
     ]
    }
   ],
   "source": [
    "msdd = MSDD(\n",
    "    threshold=0.8\n",
    ")\n",
    "titanet_l = msdd.speech_embedding_model\n",
    "vad = SileroVAD(\n",
    "    threshold=0.5\n",
    ")\n",
    "osc = OnlineSpeakerClustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9077e6-0ed5-4d3e-bfb9-4fd1a9cb9cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform, sr = load_audio('test.wav')\n",
    "waveform, sr = load_audio('toefl_eg.mp3')\n",
    "waveform = waveform[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b816c7-db8f-4b42-adb7-efa170cc7dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [1.5, 1.25, 1.0, 0.75, 0.5]\n",
    "hops = [scale/4 for scale in scales]\n",
    "a = Audio(\n",
    "    scales, \n",
    "    hops, \n",
    "    speech_embedding_model=titanet_l,\n",
    "    voice_activity_detection_model=vad,\n",
    "    multi_scale_diarization_model=msdd,\n",
    "    speaker_clustering=osc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e921416-6557-4d4f-a3e5-31bb9a169bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proba, labels = a(waveform[:500_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7bd5925f-18d4-45d5-ba7c-3951e4416fc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proba, labels = a(waveform[500_000:1_000_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2e8d7a-5f83-454f-b148-95d04bbda35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba, labels = a(waveform[1_000_000:1_500_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50ec3253-030a-45f1-8ea4-c3aa34995cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8835616-c3fa-41ee-9bb0-aee48f2bd348",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba, labels = a(waveform[1_500_000:2_000_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f21ddd1d-8f58-43d8-a787-d48fd7da183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba, labels = a(waveform[2_000_000:2_500_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fff24f3-cf53-47c8-823c-e0223b40714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba, labels = a(waveform[2_500_000:3_000_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec51d768-4644-45a2-8521-ff1bfb4da17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1356, 0.1184, 0.1050, 0.0728, 0.0698, 0.1083, 0.1571, 0.1815, 0.1480,\n",
       "         0.1260, 0.1000, 0.0785, 0.0692, 0.0671, 0.0763, 0.1061, 0.1279, 0.1478,\n",
       "         0.1541, 0.1397, 0.1148, 0.0859, 0.0604, 0.0574, 0.0763, 0.1102, 0.1314,\n",
       "         0.1270, 0.1104, 0.0994, 0.0988, 0.1265, 0.1472, 0.1454, 0.1201, 0.0955,\n",
       "         0.0785, 0.0794, 0.0824, 0.0801, 0.0832, 0.0962, 0.1112, 0.1123, 0.1176,\n",
       "         0.1222, 0.1194, 0.1233, 0.1218, 0.1262, 0.1778, 0.2016, 0.2492, 0.3240,\n",
       "         0.3829, 0.3947, 0.3751, 0.4090, 0.4461, 0.4720, 0.4768, 0.4799, 0.4867,\n",
       "         0.4858, 0.4772, 0.4742, 0.4718, 0.4533, 0.4555, 0.4554, 0.4484, 0.4550,\n",
       "         0.4608, 0.4697, 0.4680, 0.4652, 0.4675, 0.4713, 0.4619, 0.4647, 0.4651,\n",
       "         0.4572, 0.4566, 0.4589, 0.4768, 0.4685, 0.4871, 0.4799, 0.4869, 0.4577,\n",
       "         0.4359, 0.3838, 0.3241, 0.3079, 0.2992, 0.3055, 0.3413, 0.3730, 0.3566,\n",
       "         0.1730, 0.1189, 0.1059, 0.0889, 0.0762, 0.0757, 0.0776, 0.0815, 0.0763,\n",
       "         0.0684, 0.0709, 0.0827, 0.0916, 0.0961, 0.0887, 0.0696, 0.0603, 0.0628,\n",
       "         0.0705, 0.0809, 0.0933, 0.1161, 0.1406, 0.1488, 0.1801, 0.2231, 0.2429,\n",
       "         0.2272, 0.1646, 0.1149, 0.0982, 0.0999, 0.0828, 0.0768, 0.0723, 0.0808,\n",
       "         0.0854, 0.0892, 0.0786, 0.0777, 0.0721, 0.0755, 0.0764, 0.0770, 0.0768,\n",
       "         0.0766, 0.0788, 0.0787, 0.0798, 0.0800, 0.0823, 0.0890, 0.1013, 0.1120,\n",
       "         0.1176, 0.1242, 0.1163, 0.1062, 0.0876, 0.0770, 0.0668, 0.0687, 0.0718,\n",
       "         0.0739, 0.0707, 0.0698, 0.0681, 0.0685, 0.0708, 0.0736, 0.0772, 0.0792,\n",
       "         0.0801, 0.0892, 0.1096, 0.1562, 0.2234, 0.2566, 0.2475, 0.1840, 0.1248,\n",
       "         0.1062, 0.1034, 0.0970, 0.0973, 0.0910, 0.0855, 0.1218, 0.2444, 0.3518,\n",
       "         0.3571, 0.3213, 0.2131, 0.1517, 0.1307, 0.1754, 0.2608, 0.3199, 0.3047,\n",
       "         0.2597, 0.1793, 0.1551, 0.1605, 0.2067, 0.2594, 0.2545, 0.2384, 0.1939,\n",
       "         0.1870, 0.1415, 0.1350, 0.1134, 0.1067, 0.1049, 0.1211, 0.1343, 0.1456,\n",
       "         0.1405, 0.1386, 0.1281, 0.1151, 0.1110, 0.1109, 0.1182, 0.1266, 0.1375,\n",
       "         0.1288, 0.1026, 0.0819, 0.0714, 0.0708, 0.0762, 0.0917, 0.1044, 0.1109,\n",
       "         0.1114, 0.1130, 0.1198, 0.1366],\n",
       "        [0.9999, 1.0000, 1.0000, 1.0000, 0.9999, 0.9996, 0.9958, 0.9725, 0.7028,\n",
       "         0.6027, 0.5563, 0.5388, 0.5299, 0.5265, 0.5305, 0.5376, 0.5470, 0.5470,\n",
       "         0.5429, 0.5335, 0.5236, 0.5130, 0.5095, 0.5183, 0.5806, 0.8399, 0.9801,\n",
       "         0.9980, 0.9997, 0.9992, 0.9993, 0.9989, 0.9939, 0.9988, 0.9999, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9999, 0.9998,\n",
       "         0.9993, 0.9992, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 0.9999, 0.9995, 0.9897,\n",
       "         0.9197, 0.7360, 0.6474, 0.6022, 0.5811, 0.5812, 0.5792, 0.5544, 0.5224,\n",
       "         0.5090, 0.5036, 0.5028, 0.5051, 0.5100, 0.5140, 0.5099, 0.5056, 0.5038,\n",
       "         0.5029, 0.5030, 0.5084, 0.5326, 0.5674, 0.5924, 0.6072, 0.6161, 0.6112,\n",
       "         0.5958, 0.5739, 0.5587, 0.5649, 0.5842, 0.5978, 0.6072, 0.5875, 0.5666,\n",
       "         0.5480, 0.5388, 0.5316, 0.5274, 0.5162, 0.5089, 0.5043, 0.5025, 0.5020,\n",
       "         0.5021, 0.5027, 0.5029, 0.5029, 0.5033, 0.5055, 0.5110, 0.5278, 0.5550,\n",
       "         0.6048, 0.6545, 0.6642, 0.6496, 0.6263, 0.5965, 0.5522, 0.5253, 0.5165,\n",
       "         0.5167, 0.5188, 0.5183, 0.5124, 0.5071, 0.5045, 0.5038, 0.5043, 0.5062,\n",
       "         0.5088, 0.5111, 0.5143, 0.5431, 0.6514, 0.9059, 0.9826, 0.9979, 0.9997,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9997, 0.9909, 0.9755,\n",
       "         0.9716, 0.9938, 0.9990, 0.9996, 0.9999, 0.9997, 0.9996, 0.9995, 0.9988,\n",
       "         0.9982, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         0.9989, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [0.5445, 0.5261, 0.5194, 0.5336, 0.5599, 0.6380, 0.7256, 0.7788, 0.9975,\n",
       "         0.9996, 0.9999, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.9979, 0.9766, 0.9340,\n",
       "         0.8361, 0.7615, 0.7445, 0.7797, 0.8897, 0.9047, 0.8722, 0.7368, 0.5758,\n",
       "         0.5172, 0.5068, 0.5075, 0.5231, 0.5941, 0.6436, 0.6586, 0.6608, 0.6687,\n",
       "         0.6656, 0.6601, 0.6204, 0.5591, 0.5147, 0.4915, 0.4855, 0.4755, 0.4460,\n",
       "         0.3878, 0.3452, 0.3521, 0.3230, 0.3018, 0.2836, 0.2857, 0.3363, 0.3434,\n",
       "         0.3659, 0.4155, 0.4140, 0.4259, 0.4557, 0.4290, 0.4167, 0.4170, 0.4262,\n",
       "         0.4350, 0.4173, 0.4212, 0.4339, 0.3984, 0.3611, 0.3892, 0.3936, 0.3953,\n",
       "         0.3962, 0.3411, 0.2773, 0.1979, 0.2260, 0.2049, 0.2896, 0.3200, 0.4564,\n",
       "         0.4677, 0.4861, 0.5010, 0.5173, 0.5459, 0.5647, 0.6259, 0.7874, 0.8699,\n",
       "         0.9174, 0.9950, 0.9973, 0.9994, 0.9997, 0.9998, 0.9997, 0.9998, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 0.9998, 0.9999, 0.9999, 0.9997, 0.9993,\n",
       "         0.9997, 0.9999, 1.0000, 0.9999, 0.9997, 0.9997, 0.9990, 0.9999, 0.9999,\n",
       "         1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         0.9999, 0.9997, 0.9975, 0.9998, 0.9998, 0.9999, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "         1.0000, 1.0000, 1.0000, 1.0000, 0.9997, 0.9634, 0.9169, 0.8297, 0.6161,\n",
       "         0.5348, 0.5157, 0.5116, 0.5134, 0.5160, 0.5334, 0.6550, 0.8092, 0.9200,\n",
       "         0.9498, 0.9264, 0.7982, 0.6128, 0.5916, 0.6616, 0.7589, 0.8504, 0.8561,\n",
       "         0.7972, 0.6853, 0.6051, 0.5598, 0.5408, 0.5264, 0.5107, 0.5031, 0.5100,\n",
       "         0.5141, 0.5162, 0.5126, 0.5066, 0.5036, 0.5031, 0.5026, 0.5025, 0.5035,\n",
       "         0.5093, 0.5267, 0.5422, 0.5411, 0.5343, 0.5200, 0.5137, 0.5218, 0.5275,\n",
       "         0.5227, 0.5134, 0.5059, 0.5054, 0.5073, 0.5105, 0.5131, 0.5116, 0.5088,\n",
       "         0.5058, 0.5040, 0.5040, 0.5116]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3f527e6-0380-4321-b8cb-4a51988f8cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 1.0000, 1.0000,  ..., 0.1265, 0.1363, 0.1547],\n",
       "         [0.4071, 0.4726, 0.5145,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.4454, 0.3957, 0.3099,  ..., 0.5040, 0.5040, 0.5122]]),\n",
       " tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "247a64d2-e6ac-4daf-87d8-7dd0320d2aed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "proba, labels = a(waveform[1_000_000:4_000_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8e029e6-652b-4198-8ec1-45a685747a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5779, 0.6387, 0.7030,  ..., 0.7686, 0.7629, 0.7463],\n",
       "         [1.0000, 1.0000, 1.0000,  ..., 0.7863, 0.7777, 0.7710],\n",
       "         [0.7010, 0.7149, 0.7094,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.3367, 0.3425, 0.3632,  ..., 0.5455, 0.5568, 0.5384],\n",
       "         [0.3893, 0.3460, 0.3051,  ..., 0.3876, 0.3940, 0.3771],\n",
       "         [0.6612, 0.6315, 0.5984,  ..., 0.1415, 0.1071, 0.0864]]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 1., 1., 1.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(waveform[4_000_000:10_000_000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79065304-e371-412f-9f6a-8fc95947a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = a.get_merged_speaker_segments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37c121de-f6b2-41a9-b132-59607a488763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SpeakerSegment(start=0, end=17.625, data=tensor([ 0.0000,  0.0000,  0.0000,  ..., -0.0015, -0.0009, -0.0007]), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.]), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=17.875, end=50.375, data=tensor([-0.0037, -0.0012,  0.0005,  ...,  0.0037,  0.0032,  0.0023]), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.]), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=50.875, end=61.875, data=tensor([ 1.6737e-03,  3.6514e-04, -5.9805e-05,  ..., -1.1843e-03,\n",
       "         -1.0885e-03, -7.7725e-04]), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.]), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=62.375, end=93.0, data=tensor([-0.0970, -0.0802, -0.1046,  ..., -0.0864, -0.0612, -0.0339]), mask=tensor([1., 1., 1.,  ..., 1., 1., 1.]), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=93.625, end=124.375, data=tensor([ 0.0049,  0.0063,  0.0076,  ..., -0.0357, -0.0246, -0.0219]), mask=tensor([1., 1., 1.,  ..., 1., 1., 1.]), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=124.875, end=134.875, data=tensor([0.0021, 0.0020, 0.0019,  ..., 0.0000, 0.0000, 0.0000]), mask=tensor([1., 1., 1.,  ..., 0., 0., 0.]), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=136.375, end=141.0, data=tensor([-1.9263e-04, -9.7002e-05, -2.7693e-04,  ...,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00]), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.]), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=141.375, end=155.625, data=tensor([0.0000, 0.0000, 0.0000,  ..., 0.0050, 0.0054, 0.0056]), mask=tensor([0., 0., 0.,  ..., 1., 1., 1.]), speaker=0, transcription=None),\n",
       " SpeakerSegment(start=157.25, end=160.875, data=tensor([-2.6874e-05,  4.8968e-05,  4.4306e-05,  ..., -5.7348e-02,\n",
       "         -2.9683e-02, -5.8608e-04]), mask=tensor([0., 0., 0.,  ..., 0., 0., 0.]), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=159.375, end=169.125, data=tensor([-0.0878, -0.0867, -0.0853,  ..., -0.0571, -0.0752, -0.0952]), mask=tensor([1., 1., 1.,  ..., 1., 1., 1.]), speaker=1, transcription=None),\n",
       " SpeakerSegment(start=168.5, end=179.125, data=tensor([-0.0250,  0.0031,  0.0100,  ..., -0.0321, -0.0633, -0.0969]), mask=tensor([1., 1., 1.,  ..., 1., 1., 1.]), speaker=2, transcription=None),\n",
       " SpeakerSegment(start=178.375, end=186.75, data=tensor([ 0.0142,  0.0137,  0.0131,  ..., -0.0556, -0.0491, -0.0510]), mask=tensor([1., 1., 1.,  ..., 1., 1., 1.]), speaker=1, transcription=None)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89071a89-58c7-414c-8992-eb4fe84e5727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 50\n",
    "torchaudio.save('segmented.wav', merged[i].data.unsqueeze(0).cpu(), 16_000)\n",
    "merged[i].speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f99e2ad1-f074-40be-ae86-8c2499258310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542.5"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged[i].end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1726a181-c8dc-4826-9b14-ff89d0596ddf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timeline = [segment.speakers for segment in a.base_scale_segments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "590ed1cb-114e-49ae-838b-2d9cb2868b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker 0: 62.00s - 120.00s (duration: 58.00s)\n",
      "Speaker 0: 120.25s - 134.00s (duration: 13.75s)\n",
      "Speaker 0: 135.75s - 137.75s (duration: 2.00s)\n",
      "Speaker 1: 135.75s - 140.25s (duration: 4.50s)\n",
      "Speaker 1: 140.75s - 145.00s (duration: 4.25s)\n",
      "Speaker 2: 145.50s - 155.25s (duration: 9.75s)\n",
      "Speaker 2: 155.50s - 156.50s (duration: 1.00s)\n",
      "Speaker 1: 156.75s - 160.00s (duration: 3.25s)\n",
      "Speaker 2: 159.00s - 168.75s (duration: 9.75s)\n",
      "Speaker 1: 168.50s - 178.25s (duration: 9.75s)\n",
      "Speaker 2: 171.75s - 172.75s (duration: 1.00s)\n",
      "Speaker 2: 175.25s - 175.75s (duration: 0.50s)\n",
      "Speaker 2: 178.00s - 181.75s (duration: 3.75s)\n",
      "Speaker 2: 182.00s - 187.25s (duration: 5.25s)\n",
      "Speaker 1: 187.50s - 191.25s (duration: 3.75s)\n",
      "Speaker 2: 191.00s - 191.25s (duration: 0.25s)\n",
      "Speaker 1: 191.50s - 191.75s (duration: 0.25s)\n",
      "Speaker 2: 191.50s - 197.00s (duration: 5.50s)\n",
      "Speaker 1: 196.50s - 206.75s (duration: 10.25s)\n",
      "Speaker 1: 207.00s - 215.75s (duration: 8.75s)\n",
      "Speaker 2: 215.25s - 220.25s (duration: 5.00s)\n",
      "Speaker 1: 220.50s - 229.75s (duration: 9.25s)\n",
      "Speaker 2: 220.50s - 220.75s (duration: 0.25s)\n",
      "Speaker 2: 229.50s - 235.00s (duration: 5.50s)\n",
      "Speaker 1: 234.75s - 249.00s (duration: 14.25s)\n",
      "Speaker 1: 249.25s - 253.25s (duration: 4.00s)\n",
      "Speaker 2: 253.00s - 257.75s (duration: 4.75s)\n",
      "Speaker 1: 257.75s - 273.75s (duration: 16.00s)\n",
      "Speaker 2: 273.25s - 283.00s (duration: 9.75s)\n",
      "Speaker 1: 283.25s - 291.50s (duration: 8.25s)\n",
      "Speaker 2: 283.25s - 283.50s (duration: 0.25s)\n",
      "Speaker 2: 291.50s - 294.25s (duration: 2.75s)\n",
      "Speaker 1: 294.00s - 304.25s (duration: 10.25s)\n",
      "Speaker 2: 304.25s - 311.25s (duration: 7.00s)\n",
      "Speaker 1: 311.75s - 323.25s (duration: 11.50s)\n",
      "Speaker 0: 324.75s - 327.75s (duration: 3.00s)\n",
      "Speaker 1: 325.00s - 327.75s (duration: 2.75s)\n",
      "Speaker 0: 353.50s - 359.75s (duration: 6.25s)\n",
      "Speaker 1: 353.50s - 354.50s (duration: 1.00s)\n",
      "Speaker 0: 383.50s - 387.00s (duration: 3.50s)\n",
      "Speaker 0: 413.25s - 419.50s (duration: 6.25s)\n",
      "Speaker 0: 442.75s - 447.25s (duration: 4.50s)\n",
      "Speaker 1: 444.75s - 455.25s (duration: 10.50s)\n",
      "Speaker 1: 455.50s - 460.00s (duration: 4.50s)\n",
      "Speaker 1: 460.25s - 462.00s (duration: 1.75s)\n",
      "Speaker 0: 462.50s - 463.00s (duration: 0.50s)\n",
      "Speaker 1: 462.50s - 472.00s (duration: 9.50s)\n",
      "Speaker 0: 463.25s - 465.00s (duration: 1.75s)\n",
      "Speaker 1: 502.50s - 506.00s (duration: 3.50s)\n",
      "Speaker 1: 506.75s - 507.00s (duration: 0.25s)\n",
      "Speaker 2: 506.75s - 517.25s (duration: 10.50s)\n",
      "Speaker 2: 517.50s - 523.25s (duration: 5.75s)\n",
      "Speaker 2: 523.75s - 528.50s (duration: 4.75s)\n",
      "Speaker 2: 528.75s - 541.50s (duration: 12.75s)\n",
      "Speaker 2: 542.00s - 578.75s (duration: 36.75s)\n",
      "Speaker 2: 579.00s - 581.25s (duration: 2.25s)\n",
      "Speaker 2: 581.50s - 589.00s (duration: 7.50s)\n",
      "Speaker 2: 589.25s - 591.50s (duration: 2.25s)\n",
      "Speaker 2: 591.75s - 606.50s (duration: 14.75s)\n",
      "Speaker 2: 606.75s - 623.75s (duration: 17.00s)\n"
     ]
    }
   ],
   "source": [
    "def process_timeline(data):\n",
    "    # Convert None to empty list for consistency\n",
    "    timeline = [[] if x is None else sorted(x) for x in data]\n",
    "    return timeline\n",
    "\n",
    "def merge_segments(timeline):\n",
    "    merged_segments = []\n",
    "    \n",
    "    # Find continuous segments for each speaker\n",
    "    for speaker in set([spk for t in timeline for spk in t]):\n",
    "        start_idx = None\n",
    "        \n",
    "        for t, speakers in enumerate(timeline):\n",
    "            if speaker in speakers:\n",
    "                if start_idx is None:\n",
    "                    start_idx = t\n",
    "            elif start_idx is not None:\n",
    "                # Add segment\n",
    "                merged_segments.append({\n",
    "                    'speaker': speaker,\n",
    "                    'start': start_idx * 0.25,  # Convert to seconds\n",
    "                    'end': t * 0.25,            # Convert to seconds\n",
    "                    'duration': (t - start_idx) * 0.25\n",
    "                })\n",
    "                start_idx = None\n",
    "        \n",
    "        # Handle segment that goes until the end\n",
    "        if start_idx is not None:\n",
    "            merged_segments.append({\n",
    "                'speaker': speaker,\n",
    "                'start': start_idx * 0.25,\n",
    "                'end': len(timeline) * 0.25,\n",
    "                'duration': (len(timeline) - start_idx) * 0.25\n",
    "            })\n",
    "    \n",
    "    return sorted(merged_segments, key=lambda x: (x['start'], x['speaker']))\n",
    "\n",
    "def generate_rttm(segments):\n",
    "    rttm_lines = []\n",
    "    \n",
    "    for seg in segments:\n",
    "        rttm_line = f\"SPEAKER unknown 1 {seg['start']:.3f} {seg['duration']:.3f} <NA> <NA> SPEAKER_{seg['speaker']} <NA> <NA>\"\n",
    "        rttm_lines.append(rttm_line)\n",
    "    \n",
    "    return \"\\n\".join(rttm_lines)\n",
    "\n",
    "def create_visualization(segments, total_duration):\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    \n",
    "    # Get unique speakers and assign them y-coordinates\n",
    "    unique_speakers = sorted(set(seg['speaker'] for seg in segments))\n",
    "    speaker_to_y = {speaker: i for i, speaker in enumerate(unique_speakers)}\n",
    "    \n",
    "    # Create line segments for each speaker\n",
    "    for speaker in unique_speakers:\n",
    "        speaker_segments = [seg for seg in segments if seg['speaker'] == speaker]\n",
    "        \n",
    "        for seg in speaker_segments:\n",
    "            plt.hlines(\n",
    "                y=speaker_to_y[seg['speaker']],\n",
    "                xmin=seg['start'],\n",
    "                xmax=seg['end'],\n",
    "                linewidth=4,\n",
    "                label=f\"Speaker {speaker}\"\n",
    "            )\n",
    "    \n",
    "    # Set axis limits to show the full timeline\n",
    "    plt.xlim(0, total_duration)\n",
    "    plt.ylim(-0.5, len(unique_speakers) - 0.5)\n",
    "    \n",
    "    # Set y-axis labels\n",
    "    plt.yticks(\n",
    "        range(len(unique_speakers)),\n",
    "        [f\"Speaker {speaker}\" for speaker in unique_speakers]\n",
    "    )\n",
    "    \n",
    "    # Remove duplicate labels in legend\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    plt.legend(by_label.values(), by_label.keys(), loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.xlabel(\"Time (seconds)\")\n",
    "    plt.ylabel(\"Speakers\")\n",
    "    plt.title(\"Speaker Diarization Timeline\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add some padding to the plot\n",
    "    plt.margins(x=0.02)\n",
    "    \n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig('speaker_diarization.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Use your existing code to process the data and generate segments\n",
    "timeline = process_timeline(timeline)\n",
    "merged_segments = merge_segments(timeline)\n",
    "\n",
    "# Calculate total duration in seconds\n",
    "total_duration = len(timeline) * 0.25\n",
    "\n",
    "# Generate RTTM\n",
    "rttm_content = generate_rttm(merged_segments)\n",
    "with open('output.rttm', 'w') as f:\n",
    "    f.write(rttm_content)\n",
    "\n",
    "# Create visualization with total duration\n",
    "create_visualization(merged_segments, total_duration)\n",
    "\n",
    "# Print segments for verification\n",
    "for seg in merged_segments:\n",
    "    print(f\"Speaker {seg['speaker']}: {seg['start']:.2f}s - {seg['end']:.2f}s (duration: {seg['duration']:.2f}s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6b30a9-a069-489c-8b8a-d7796b7fdc07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
